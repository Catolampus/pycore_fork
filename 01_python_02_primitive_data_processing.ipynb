{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Срез (slice)\n",
    "\n",
    "Самый простой метод обработки данных, просто возвращает ту часть данных, местоположение которой (индексы) удовлетворяет определенным условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box with five \n",
      " box with five dozen liquor jugs \n",
      " Pack my box with five \n",
      " Pack my box with five dozen liquor jugs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a:str = \"Pack my box with five dozen liquor jugs\"\n",
    "\n",
    "start, stop = 8, 21\n",
    "\n",
    "b:str = a[start:stop]  # Значения от start до stop-1\n",
    "c:str = a[start:]  # Значения от start до конца структуры\n",
    "d:str = a[:stop]  # Значения от начала до stop-1\n",
    "e:str = a[:]  # Полная копия структуры\n",
    "\n",
    "print(b, \"\\n\",\n",
    "      c, \"\\n\",\n",
    "      d, \"\\n\",\n",
    "      e, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения start и stop могут быть отрицательными, это будет означать, что отсчет ведется от конца структуры. Можно также использовать значение step, чтобы на выход среза попали не все подряд данные из входной структуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pets \n",
      " step on no petS \n",
      "  petS \n",
      " Se nn es \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a:str = \"Step on no pets\"\n",
    "\n",
    "b:str = a[-4:]  # «Хвостик»\n",
    "c:str = a[::-1]  # Реверс входной строки\n",
    "d:str = a[4::-1]  # Первые четыре значения, реверсированы\n",
    "e:str = a[::2]  # Каждый второй символ\n",
    "\n",
    "print(b, \"\\n\",\n",
    "      c, \"\\n\",\n",
    "      d, \"\\n\",\n",
    "      e, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension\n",
    "\n",
    "Comprehension, которое переводится то как списковое включение, то как абстракция списков ([Википедия](https://ru.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BA%D0%BE%D0%B2%D0%BE%D0%B5_%D0%B2%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)), то вообще никак не переводится — способ компактного описания операций обработки списков (а примениительно к Python — еще и словарей, и множеств).\n",
    "\n",
    "Проще говоря, если вам нужно получить из списка другой список, включающий только те значения, которые удовлетворяют какому-то определенному условию, или вычисляемый из первого списка по каким-то определенным правилам, то comprehension — претендент на решение этой задачи № 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \n",
      " {8, 9, 6, 7} \n",
      " [5, 7, 9, 11, 13, 15, 17, 19, 21, 23] \n",
      " {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n"
     ]
    }
   ],
   "source": [
    "# Примеры Comprehension\n",
    "\n",
    "a = [i+1 for i in range(10)]  # list\n",
    "b  = {i for i in range(10) if i > 5}  # set\n",
    "c = (2*i+5 for i in range(10))  # iter\n",
    "d = {i: i**2 for i in range(10)}  # dict\n",
    "\n",
    "print(a,\"\\n\", b, \"\\n\", list(c), \"\\n\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут главное не перегнуть палку. Если запись comprehension становится слишком сложной и нечитаемой, возможно, стоит развернуть логику в «нормальный» цикл или в другой более удобочитаемый алгоритм. Comprehension соблазняет записывать «однострочникоми» достаточно сложные выражения, но не забывайте, что программист примерно 90 % времени читает код, и только 10 % пишет, так что если выражение будет плохочитаемым, вы усложните жизнь и себе, и свои коллегам.\n",
    "\n",
    "Есть более-менее [удачные](https://leetcode.com/problems/flipping-an-image/discuss/2378360/python-1-liner-988-speed-97-mem) «однострочники», есть быстрые, но [плохочитаемые](https://leetcode.com/problems/reverse-string-ii/discuss/2281269/python-fast-beats-984-and-short-almost-1-line-solution-with-python-38-features-pep572), написанные из спортивного интереса (это ссылки на решенные мной задачки на leetcode), желательно использовать comprehension в меру; лучше написать понятный развернутый алгоритм, чем непонятный, но обложенный пояснениями (если нет особых требований к производительности, само собой).\n",
    "\n",
    "Еще немного про list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lemon', 'Apple', 'Watermelon', 'Pear']\n",
      "['LEMON', 'APPLE', 'BANANA', 'KIWI', 'WATERMELON', 'PEAR']\n",
      "[['Lemon', 'Apple'], ['Banana', 'Kiwi'], ['Watermelon', 'Pear']]\n"
     ]
    }
   ],
   "source": [
    "# new_list = [expression for member in iterable (if conditional)]\n",
    "\n",
    "fruits: list = [\"Lemon\", \"Apple\", \"Banana\", \"Kiwi\", \"Watermelon\", \"Pear\"]\n",
    "\n",
    "e_fruits = [fruit for fruit in fruits if \"e\" in fruit]\n",
    "#                                     ☝ if conditional\n",
    "print(e_fruits)\n",
    "\n",
    "upper_fruits = [fruit.upper() for fruit in fruits]\n",
    "#                     ☝ expression\n",
    "print(upper_fruits)\n",
    "\n",
    "# Split a list into equal sized chunks\n",
    "chunk_len = 2\n",
    "chunk_fruits = [fruits[i:i + chunk_len] for i in range(0, len(fruits), chunk_len)]\n",
    "print(chunk_fruits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Italy': 'Pizza', 'US': 'Hot-Dog', 'China': 'Dim Sum', 'South Korea': 'Kimchi'}\n",
      "{'Italy': 'Pizza', 'China': 'Dim Sum', 'South Korea': 'Kimchi'}\n",
      "{'China': 'Dim Sum'}\n",
      "{'US': 'Hot-Dog', 'China': 'Dim Sum'}\n"
     ]
    }
   ],
   "source": [
    "# new_dict = {expression for member in iterable (if conditional)}\n",
    "\n",
    "d: dict = {\"Italy\": \"Pizza\", \"US\": \"Hot-Dog\", \"China\": \"Dim Sum\", \"South Korea\": \"Kimchi\"}  # Create a dictionary\n",
    "print(d)\n",
    "\n",
    "a: dict = {k: v for k, v in d.items() if \"i\" in v}  # Вернет новый словарь, отфильтрованный по значению\n",
    "print(a)\n",
    "\n",
    "b: dict = {k: v for k, v in d.items() if \"i\" in k}  # Вернет новый словарь, отфильтрованный по ключу\n",
    "print(b)\n",
    "\n",
    "c: dict = {k: v for k, v in d.items() if len(v) >= 7}  # Вернет новый словарь, отфильтрованный по длине значений\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum, Count, Min, Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "3\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a: list[int] = [1, 2, 3, 4, 5, 2, 2]\n",
    "\n",
    "s = sum(a)\n",
    "print(s)\n",
    "\n",
    "c = a.count(2)  # Returns number of occurrences\n",
    "print(c)\n",
    "\n",
    "mn = min(a)\n",
    "print(mn)\n",
    "\n",
    "mx = max(a)\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Filter, Reduce\n",
    " \n",
    "<iter> = map(lambda x: x + 1, range(10))                  # (1, 2, ..., 10)  \n",
    "<iter> = filter(lambda x: x > 5, range(10))               # (6, 7, 8, 9)  \n",
    "<obj>  = reduce(lambda out, x: out + x, range(10))        # 45  \n",
    " \n",
    "Reduce must be imported from the functools module.  \n",
    "\n",
    "### Any, All\n",
    " \n",
    "<bool> = any(<collection>)                                # Is `bool(el)` True for any element.  \n",
    "<bool> = all(<collection>)                                # Is True for all elements or empty.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted_by_second = sorted(<collection>, key=lambda el: el[1])  \n",
    "sorted_by_both   = sorted(<collection>, key=lambda el: (el[1], el[0]))  \n",
    "flatter_list     = list(itertools.chain.from_iterable(<list>))  \n",
    "product_of_elems = functools.reduce(lambda out, el: out * el, <collection>)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itertools\n",
    " \n",
    "from itertools import count, repeat, cycle, chain, islice\n",
    "\n",
    "<iter> = count(start=0, step=1)             # Returns updated value endlessly. Accepts floats.  \n",
    "<iter> = repeat(<el> [, times])             # Returns element endlessly or 'times' times.  \n",
    "<iter> = cycle(<collection>)                # Repeats the sequence endlessly.  \n",
    "\n",
    "<iter> = chain(<coll_1>, <coll_2> [, ...])  # Empties collections in order (figuratively).  \n",
    "<iter> = chain.from_iterable(<collection>)  # Empties collections inside a collection in order.  \n",
    "\n",
    "<iter> = islice(<coll>, to_exclusive)       # Only returns first 'to_exclusive' elements.  \n",
    "<iter> = islice(<coll>, from_inclusive, …)  # `to_exclusive, step_size`.  \n",
    "\n",
    " \n",
    ">>> from collections.abc import Iterable, Collection, Sequence  \n",
    ">>> isinstance([1, 2, 3], Iterable)  \n",
    "True  \n",
    "\n",
    " text\n",
    "+------------------+------------+------------+------------+\n",
    "|                  |  Iterable  | Collection |  Sequence  |\n",
    "+------------------+------------+------------+------------+\n",
    "| list, range, str |    yes     |    yes     |    yes     |\n",
    "| dict, set        |    yes     |    yes     |            |\n",
    "| iter             |    yes     |            |            |\n",
    "+------------------+------------+------------+------------+\n",
    "\n",
    ">>> from numbers import Number, Complex, Real, Rational, Integral  \n",
    ">>> isinstance(123, Number)  \n",
    "True\n",
    "\n",
    " text\n",
    "+--------------------+----------+----------+----------+----------+----------+\n",
    "|                    |  Number  |  Complex |   Real   | Rational | Integral |\n",
    "+--------------------+----------+----------+----------+----------+----------+\n",
    "| int                |   yes    |   yes    |   yes    |   yes    |   yes    |\n",
    "| fractions.Fraction |   yes    |   yes    |   yes    |   yes    |          |\n",
    "| float              |   yes    |   yes    |   yes    |          |          |\n",
    "| complex            |   yes    |   yes    |          |          |          |\n",
    "| decimal.Decimal    |   yes    |          |          |          |          |\n",
    "+--------------------+----------+----------+----------+----------+----------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (2, 3), (3, 4), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "p = itertools.pairwise(a)  # Returns successive overlapping pairs\n",
    "\n",
    "print(list(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Комбинаторика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n",
      "[('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'b'), ('b', 'c'), ('c', 'a'), ('c', 'b'), ('c', 'c')]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n",
      "[('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'b'), ('b', 'c'), ('c', 'c')]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'c'), ('c', 'a'), ('c', 'b')]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, combinations, combinations_with_replacement, permutations\n",
    "\n",
    "a = product([0, 1], repeat=3)\n",
    "print(list(a))\n",
    "\n",
    "b = product(\"abc\", \"abc\")\n",
    "print(list(b))\n",
    "\n",
    "c = combinations(\"abc\", 2)\n",
    "print(list(c))\n",
    "\n",
    "d = combinations_with_replacement(\"abc\", 2)\n",
    "print(list(d))\n",
    "\n",
    "e = permutations(\"abc\", 2)\n",
    "print(list(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Struct\n",
    "\n",
    "Module that performs conversions between a sequence of numbers and a bytes object. System’s type sizes and byte order are used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04'\n",
      "(1, 2, 3, 4)\n",
      "b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00'\n",
      "[(1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "from struct import pack, unpack, iter_unpack\n",
    "\n",
    "b = pack(\">hhll\", 1, 2, 3, 4)\n",
    "print(b)\n",
    "\n",
    "t = unpack(\">hhll\", b)\n",
    "print(t)\n",
    "\n",
    "i = pack(\"ii\", 1, 2) * 5\n",
    "print(i)\n",
    "\n",
    "print(list(iter_unpack('ii', i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bisect и бинарный поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [1, 6, 8, 12, 19, 33]\n",
      "5\n",
      "[1, 6, 8, 12, 15, 19, 33]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "a: list[int] = [12, 6, 8, 19, 1, 33]\n",
    "\n",
    "a.sort()\n",
    "print(f\"Sorted: {a}\")\n",
    "\n",
    "print(bisect.bisect(a, 19))  # Locate the insertion point for value in a list to maintain sorted order\n",
    "\n",
    "bisect.insort(a, 15)  # Insert value in a list in sorted order\n",
    "print(a)\n",
    "\n",
    "# Binary search\n",
    "\n",
    "from bisect import bisect_left\n",
    "\n",
    "def binary_search(a, x, lo=0, hi=None):\n",
    "    if hi is None:\n",
    "        hi = len(a)\n",
    "\n",
    "    pos = bisect_left(a, x, lo, hi)\n",
    "    return pos if pos != hi and a[pos] == x else -1\n",
    "\n",
    "print(binary_search(a, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime encode\n",
    "\n",
    "Python uses the Unix Epoch: \"1970-01-01 00:00 UTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-04 00:05:23.555000+00:00\n",
      " 2004-10-21 17:30:00\n",
      " 0274-10-16 00:00:00\n",
      " 1970-08-20 16:33:20.010000\n",
      " 1979-07-05 10:20:00+05:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "dt1: datetime = datetime.fromisoformat(\"2021-10-04 00:05:23.555+00:00\")  # Raises ValueError\n",
    "dt2: datetime = datetime.strptime(\"21/10/04 17:30\", \"%d/%m/%y %H:%M\")   # Datetime from str, according to format (https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes)\n",
    "dt3: datetime = datetime.fromordinal(100000)  # 100000th day after 1.1.0001\n",
    "dt4: datetime = datetime.fromtimestamp(20_000_000.01)  # Local datetime from seconds since the Epoch\n",
    "\n",
    "tz2: tzinfo = tzlocal()\n",
    "dt5: datetime = datetime.fromtimestamp(300_000_000, tz2)  # Aware datetime from seconds since the Epoch\n",
    "\n",
    "print (f\"{dt1}\\n {dt2}\\n {dt3}\\n {dt4}\\n {dt5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-06 17:50:38.041159\n",
      " 2022-09-06T17:50:38.041159\n",
      " 06/09/22 17:50\n",
      " 738404\n",
      " 1662468638.041159\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt1: datetime = datetime.today()\n",
    "\n",
    "s1: str = dt1.isoformat()\n",
    "s2: str = dt1.strftime(\"%d/%m/%y %H:%M\")  # Outputting datetime object to string (format: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes)\n",
    "i: int = dt1.toordinal()  # Days since Gregorian NYE 1, ignoring time and tz\n",
    "a: float = dt1.timestamp()  # Seconds since the Epoch\n",
    "\n",
    "print (f\"{dt1}\\n {s1}\\n {s2}\\n {i}\\n {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Арифметика datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11\n",
      " 2022-09-01 17:50:38.132916\n",
      " 14888 days, 17:50:38.132916\n",
      " 50 days, 0:00:00\n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, time, datetime, timedelta\n",
    "from dateutil.tz import UTC, tzlocal, gettz, datetime_exists, resolve_imaginary\n",
    "\n",
    "d: date  = date.today()\n",
    "dt1: datetime = datetime.today()\n",
    "dt2: datetime = datetime(year=1981, month=12, day=2)\n",
    "td1: timedelta = timedelta(days=5)\n",
    "td2: timedelta = timedelta(days=1)\n",
    "\n",
    "d = d + td1  # date = date ± timedelta\n",
    "dt3 = dt1 - td1  # datetime = datetime ± timedelta\n",
    "\n",
    "td3 = dt1 - dt2  # timedelta = datetime - datetime\n",
    "\n",
    "td4 = 10 * td1  # timedelta = const * timedelta\n",
    "c: float = td1/td2  # timedelta/timedelta\n",
    "\n",
    "print (f\"{d}\\n {dt3}\\n {td3}\\n {td4}\\n {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Математика\n",
    "\n",
    "### Базовая математика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power: 9.869604401089358\n",
      "Round: 3.14\n",
      "Int round: 300\n",
      "Abs: 3.141592653589793\n",
      "Complex abs: 14.142135623730951\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "\n",
    "a: float = pi ** 2  # Or pow(pi, 2)\n",
    "print(f\"Power: {a}\")\n",
    "\n",
    "b: float = round(pi, 2)\n",
    "print(f\"Round: {b}\")\n",
    "\n",
    "c: int = round(256, -2)\n",
    "print(f\"Int round: {c}\")\n",
    "\n",
    "d: float = abs(-pi)\n",
    "print(f\"Abs: {d}\")\n",
    "\n",
    "e: float = abs(10+10j)  # Or e: float = abs(complex(real=10, imag=10))\n",
    "print(f\"Complex abs: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Побитовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And: 0b00000000\n",
      "Or: 0b11111111\n",
      "Xor: 0b11111111\n",
      "Left shift: 0b10101010000\n",
      "Right shift: 0b00001010\n",
      "Not: 0b-1010110\n"
     ]
    }
   ],
   "source": [
    "a: int = 0b01010101\n",
    "b: int = 0b10101010\n",
    "\n",
    "print(f\"And: 0b{a&b:08b}\")\n",
    "print(f\"Or: 0b{a|b:08b}\")\n",
    "print(f\"Xor: 0b{a^b:08b}\")\n",
    "print(f\"Left shift: 0b{a << 4:08b}\")\n",
    "print(f\"Right shift: 0b{b >> 4:08b}\")\n",
    "print(f\"Not: 0b{~a:08b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет битов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4242 in binary format: 0b1000010010010\n",
      "Bit count: 4\n"
     ]
    }
   ],
   "source": [
    "a: int = 4242\n",
    "print(f\"{a} in binary format: 0b{a:b}\")\n",
    "\n",
    "c = a.bit_count()  # Returns the number of ones in the binary representation of the absolute value of the integer\n",
    "print(f\"Bit count: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "f = Fraction(\"0.2\").as_integer_ratio()\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Евклидово расстояние между двумя точками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.39588732276722\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "p1 = (0.22, 1, 12)\n",
    "p2 = (-0.12, 3, 7)\n",
    "\n",
    "print(math.dist(p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower(), upper(), capitalize() и title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelcase string\n",
      "CAMELCASE STRING\n",
      "Camelcase string\n",
      "Camelcase String\n"
     ]
    }
   ],
   "source": [
    "s: str = \"camelCase string\"\n",
    "\n",
    "print(s.lower())\n",
    "print(s.upper())\n",
    "print(s.capitalize())\n",
    "print(s.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Methods\n",
    "\n",
    "```text\n",
    "+---------------+----------+----------+----------+----------+----------+\n",
    "|               | [ !#$%…] | [a-zA-Z] |  [½¼¾]   |  [²³¹]   |  [0-9]   |\n",
    "+---------------+----------+----------+----------+----------+----------+\n",
    "| isprintable() |    +     |    +     |    +     |    +     |    +     |\n",
    "| isalnum()     |          |    +     |    +     |    +     |    +     |\n",
    "| isnumeric()   |          |          |    +     |    +     |    +     |\n",
    "| isdigit()     |          |          |          |    +     |    +     |\n",
    "| isdecimal()   |          |          |          |          |    +     |\n",
    "+---------------+----------+----------+----------+----------+----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~##A big blahblahblah##~~\n",
      "A big blahblahblah\n",
      "big blahblahblah\n",
      "big \n"
     ]
    }
   ],
   "source": [
    "s: str = \"  ~~##A big blahblahblah##~~  \"\n",
    "\n",
    "s = s.strip()  # Strips all whitespace characters from both ends\n",
    "print(s)\n",
    "\n",
    "s = s.strip(\"~#\")  # Strips all passed characters from both ends\n",
    "print(s)\n",
    "\n",
    "s = s.lstrip(\" A\")  # Strips all passed characters from left end\n",
    "print(s)\n",
    "\n",
    "s = s.rstrip(\"habl\")  # Strips all passed characters from right end\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Follow', 'the', 'white', 'rabbit,', 'Neo']\n",
      "['Follow the white rabbit', 'Neo']\n",
      "['Beware the Jabberwock, my son!', ' The jaws that bite, the claws that catch!']\n",
      "['Beware', 'the', 'Jabberwock, my son!\\n The jaws that bite, the claws that catch!'] ['Beware the Jabberwock, my son!\\n The jaws that bite, the claws', 'that', 'catch!']\n"
     ]
    }
   ],
   "source": [
    "s1: str = \"Follow the white rabbit, Neo\"\n",
    "\n",
    "c1 = s1.split()  # Splits on one or more whitespace characters\n",
    "print(c1)\n",
    "\n",
    "c2 = s1.split(sep=\", \", maxsplit=1)  # Splits on \"sep\" str at most \"maxsplit\" times\n",
    "print(c2)\n",
    "\n",
    "s2: str = \"Beware the Jabberwock, my son!\\n The jaws that bite, the claws that catch!\"\n",
    "\n",
    "c3 = s2.splitlines(keepends=False)  # On [\\n\\r\\f\\v\\x1c-\\x1e\\x85\\u2028\\u2029] and \\r\\n.\n",
    "print(c3)\n",
    "\n",
    "# split() vs rsplit()\n",
    "\n",
    "c4 = s2.split(maxsplit=2)\n",
    "c5 = s2.rsplit(maxsplit=2)\n",
    "\n",
    "print(c4, c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ord(), chr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 97\n",
      "b -> 98\n",
      "c -> 99\n",
      "A -> 65\n",
      "B -> 66\n",
      "C -> 67\n",
      "! -> 33\n",
      "72 -> H\n",
      "101 -> e\n",
      "108 -> l\n",
      "108 -> l\n",
      "111 -> o\n",
      "33 -> !\n"
     ]
    }
   ],
   "source": [
    "s1: str = \"abcABC!\"\n",
    "\n",
    "for ch in s1:\n",
    "    print(f\"{ch} -> {ord(ch)}\")  # Returns an integer representing the Unicode character\n",
    "\n",
    "nums = [72, 101, 108, 108, 111, 33]\n",
    "\n",
    "for num in nums:\n",
    "    print(f\"{num} -> {chr(num)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex\n",
    "\n",
    "Argument flags=re.IGNORECASE can be used with all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 5), match='a'>\n",
      "a\n",
      "None\n",
      "['a', 'A']\n",
      "234 bcd BCD 567\n",
      "['', '', '', ' abc ABC ', '', '', '']\n",
      " abc ABC "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s1: str = \"123 abc ABC 456\"\n",
    "\n",
    "m1 = re.search(\"[aA]\", s1)  # Searches for first occurrence of the pattern; search() return None if it can't find a match\n",
    "print(m1)\n",
    "print(m1.group(0))\n",
    "\n",
    "m2 = re.match(\"[aA]\", s1)  # Searches at the beginning of the text; match() return None if it can't find a match\n",
    "print(m2)\n",
    "\n",
    "c1: list = re.findall(\"[aA]\", s1)  # Returns all occurrences as strings\n",
    "print(c1)\n",
    "\n",
    "def replacer(s):  # replacer() can be a function that accepts a match object and returns a string\n",
    "    return chr(ord(s[0]) + 1)  # Next symbol in alphabet\n",
    "\n",
    "s2 = re.sub(\"\\w\", replacer, s1)  # Substitutes all occurrences with 'replacer'\n",
    "print(s2)\n",
    "\n",
    "c2 = re.split(\"\\d\", s1)\n",
    "print(c2)\n",
    "\n",
    "iter = re.finditer(\"\\D\", s1)  # Returns all occurrences as match objects\n",
    "\n",
    "for ch in iter:\n",
    "    print(ch.group(0), end= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Connor\n",
      " John\n",
      " ('John', 'Connor')\n",
      " 0\n",
      " 11\n",
      " (0, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "m3 = re.match(r\"(\\w+) (\\w+)\", \"John Connor, leader of the Resistance\")\n",
    "\n",
    "s3: str = m3.group(0)  # Returns the whole match\n",
    "s4: str = m3.group(1)  # Returns part in the first bracket\n",
    "t1: tuple = m3.groups()  # Returns all bracketed parts\n",
    "start: int = m3.start()  # Returns start index of the match\n",
    "end: int = m3.end()  # Returns exclusive end index of the match\n",
    "t2: tuple[int, int] = m3.span()  # Return the 2-tuple (start, end)\n",
    "\n",
    "print (f\"{s3}\\n {s4}\\n {t1}\\n {start}\\n {end}\\n {t2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File\n",
    "\n",
    "### Open\n",
    "\n",
    "Open the file and return a corresponding file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from file!\n"
     ]
    }
   ],
   "source": [
    "f = open(\"f.txt\", mode='r', encoding=\"utf-8\", newline=None)\n",
    "\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*encoding=None* means that the default encoding is used, which is platform dependent. Best practice is to use *encoding=\"utf-8\"* whenever possible.  \n",
    "*newline=None* means all different end of line combinations are converted to '\\n' on read, while on write all '\\n' characters are converted to system's default line separator.  \n",
    "*newline=\"\"* means no conversions take place, but input is still broken into chunks by readline() and readlines() on every \"\\n\", \"\\r\" and \"\\r\\n\".  \n",
    "\n",
    "### Режимы\n",
    "\n",
    "\"r\" - Read (default)  \n",
    "\"w\" - Write (truncate)  \n",
    "\"x\" - Write or fail if the file already exists  \n",
    "\"a\" - Append  \n",
    "\"w+\" - Read and write (truncate)  \n",
    "\"r+\" - Read and write from the start  \n",
    "\"a+\" - Read and write from the end  \n",
    "\"t\" - Text mode (default)  \n",
    "\"b\" - Binary mode (`'br'`, `'bw'`, `'bx'`, …)  \n",
    "\n",
    "### Исключения\n",
    "\n",
    "*FileNotFoundError* can be raised when reading with \"r\" or \"r+\".  \n",
    "*FileExistsError* can be raised when writing with \"x\".  \n",
    "*IsADirectoryError* and *PermissionError* can be raised by any.  \n",
    "*OSError* is the parent class of all listed exceptions.  \n",
    "\n",
    "### Чтение из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "['Hello from file!']\n"
     ]
    }
   ],
   "source": [
    "with open(\"f.txt\", encoding=\"utf-8\") as f:\n",
    "    chars = f.read(5)  # Reads chars/bytes or until EOF\n",
    "    print(chars)\n",
    "\n",
    "    f.seek(0)  # Moves to the start of the file. Also seek(offset) and seek(±offset, anchor), where anchor is 0 for start, 1 for current position and 2 for end\n",
    "\n",
    "    lines: list[str] = f.readlines()  # Also readline()\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Hello from file!\")  # Also f.writelines(<collection>)\n",
    "    # f.flush() for flushes write buffer; runs every 4096/8192 B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Works\\amaargiru\\pycore\n",
      "c:\\Works\\amaargiru\\pycore\\f.txt\n",
      "f.txt c:\\Works\\amaargiru\\pycore ('c:\\\\Works\\\\amaargiru\\\\pycore\\\\f', '.txt')\n",
      "os.stat_result(st_mode=33206, st_ino=2251799814917120, st_dev=3628794147, st_nlink=1, st_uid=0, st_gid=0, st_size=16, st_atime=1662468638, st_mtime=1662468638, st_ctime=1661089564)\n",
      "True True False\n",
      "['.git', '.gitignore', '.pytest_cache', '01_python.ipynb', '01_python.md', '02_postgre.md', '03_architecture.md', '04_algorithms.ipynb', '04_algorithms.md', '05_admin_devops.md', '06_pytest_mock.ipynb', '06_pytest_mock.md', '07_fastapi.md', '08_flask.md', '1.bin', '1.json', 'compose_readme.bat', 'coupling_vs_cohesion.svg', 'f.txt', 'gitflow.svg', 'graph_for_dfs.jpg', 'pycallgraph3.png', 'readme.md']\n",
      "f .txt ('c:\\\\', 'Works', 'amaargiru', 'pycore', 'f.txt')\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, path, listdir\n",
    "from pathlib import Path\n",
    "\n",
    "s1: str = getcwd()  # Returns the current working directory\n",
    "print(s1)\n",
    "\n",
    "s2: str = path.abspath(\"f.txt\")  # Returns absolute path\n",
    "print(s2)\n",
    "\n",
    "s3: str = path.basename(s2)  # Returns final component of the path\n",
    "s4: str = path.dirname(s2)  # Returns path without the final component\n",
    "t1: tuple = path.splitext(s2)  # Splits on last period of the final component\n",
    "print(s3, s4, t1)\n",
    "\n",
    "p = Path(s2)\n",
    "st = p.stat()\n",
    "print(st)\n",
    "\n",
    "b1: bool = p.exists()\n",
    "b2: bool = p.is_file()\n",
    "b3: bool = p.is_dir()\n",
    "print(b1, b2, b3)\n",
    "\n",
    "c: list = listdir(path=s1)  # Returns filenames located at path\n",
    "print(c)\n",
    "\n",
    "s5: str = p.stem  # Returns final component without extension\n",
    "s6: str  = p.suffix  # Returns final component's extension\n",
    "t2: tuple = p.parts  # Returns all components as strings\n",
    "print(s5, s6, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "Human-readable text format to store and transmit data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"1\": \"Lemon\",\n",
      "  \"2\": \"Apple\",\n",
      "  \"3\": \"Banana!\"\n",
      "}\n",
      "{'1': 'Lemon', '2': 'Apple', '3': 'Banana!'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "d: dict = {1: \"Lemon\", 2: \"Apple\", 3: \"Banana!\"}\n",
    "\n",
    "object_as_string: str = json.dumps(d, indent=2)\n",
    "print(object_as_string)\n",
    "\n",
    "restored_object = json.loads(object_as_string)\n",
    "\n",
    "# Write object to JSON file\n",
    "with open(\"1.json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(d, file, indent=2)\n",
    "\n",
    "# Read object from JSON file\n",
    "with open(\"1.json\", encoding='utf-8') as file:\n",
    "    restored_from_file = json.load(file)\n",
    "    \n",
    "print(restored_from_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle\n",
    "\n",
    "Бинарный формат для хранения и транспортировки структур данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Lemon', 2: 'Apple', 3: 'Banana!'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "d: dict = {1: \"Lemon\", 2: \"Apple\", 3: \"Banana!\"}\n",
    "\n",
    "# Запись объекта в бинарный файл\n",
    "with open(\"1.bin\", \"wb\") as file:\n",
    "    pickle.dump(d, file)\n",
    "\n",
    "# Чтение объекта из файла\n",
    "with open(\"1.bin\", \"rb\") as file:\n",
    "    restored_from_file = pickle.load(file)\n",
    "\n",
    "print(restored_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Buffers\n",
    "Если вы хотите передавать и хранить данные, используя универсальную структуру, одинаково хорошо понимаемую всеми языками программирования (как JSON) и занимающую мало места (как Pickle), то можно посмотреть в сторону Protocol Buffers ([Wikipedia](https://en.wikipedia.org/wiki/Protocol_Buffers), [примеры для Python](https://developers.google.com/protocol-buffers/docs/pythontutorial)). Есть еще альтернативы, например, [FlatBuffers](https://google.github.io/flatbuffers/), [Apache Avro](https://avro.apache.org/) или [Thrift](https://thrift.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "Array manipulation mini-language. It can run up to one hundred times faster than the equivalent Python code. An even faster alternative that runs on a GPU is called CuPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "# $ pip3 install numpy\n",
    "import numpy as np\n",
    " \n",
    "\n",
    " \n",
    "<array> = np.array(<list/list_of_lists>)\n",
    "<array> = np.arange(from_inclusive, to_exclusive, ±step_size)\n",
    "<array> = np.ones(<shape>)\n",
    "<array> = np.random.randint(from_inclusive, to_exclusive, <shape>)\n",
    " \n",
    "\n",
    " \n",
    "<array>.shape = <shape>\n",
    "<view>  = <array>.reshape(<shape>)\n",
    "<view>  = np.broadcast_to(<array>, <shape>)\n",
    " \n",
    "\n",
    " \n",
    "<array> = <array>.sum(axis)\n",
    "indexes = <array>.argmin(axis)\n",
    " \n",
    "\n",
    "Shape is a tuple of dimension sizes.\n",
    "Axis is an index of the dimension that gets collapsed. Leftmost dimension has index 0.\n",
    "\n",
    "### Indexing\n",
    " bash\n",
    "<el>       = <2d_array>[row_index, column_index]\n",
    "<1d_view>  = <2d_array>[row_index]\n",
    "<1d_view>  = <2d_array>[:, column_index]\n",
    " \n",
    "\n",
    " bash\n",
    "<1d_array> = <2d_array>[row_indexes, column_indexes]\n",
    "<2d_array> = <2d_array>[row_indexes]\n",
    "<2d_array> = <2d_array>[:, column_indexes]\n",
    " \n",
    "\n",
    " bash\n",
    "<2d_bools> = <2d_array> ><== <el>\n",
    "<1d_array> = <2d_array>[<2d_bools>]\n",
    " \n",
    "\n",
    "### Broadcasting\n",
    "Broadcasting is a set of rules by which NumPy functions operate on arrays of different sizes and/or dimensions.\n",
    "\n",
    " \n",
    "left  = [[0.1], [0.6], [0.8]]        # Shape: (3, 1)\n",
    "right = [ 0.1 ,  0.6 ,  0.8 ]        # Shape: (3)\n",
    " \n",
    "\n",
    "#### 1. If array shapes differ in length, left-pad the shorter shape with ones:\n",
    " \n",
    "left  = [[0.1], [0.6], [0.8]]        # Shape: (3, 1)\n",
    "right = [[0.1 ,  0.6 ,  0.8]]        # Shape: (1, 3) <- !\n",
    " \n",
    "\n",
    "#### 2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:\n",
    " \n",
    "left  = [[0.1, 0.1, 0.1], [0.6, 0.6, 0.6], [0.8, 0.8, 0.8]]  # Shape: (3, 3) <- !\n",
    "right = [[0.1, 0.6, 0.8], [0.1, 0.6, 0.8], [0.1, 0.6, 0.8]]  # Shape: (3, 3) <- !\n",
    " \n",
    "\n",
    "#### 3. If neither non-matching dimension has size 1, raise an error.\n",
    "\n",
    "\n",
    "### Example\n",
    "#### For each point returns index of its nearest point (`[0.1, 0.6, 0.8] => [1, 2, 1]`):\n",
    "\n",
    " \n",
    ">>> points = np.array([0.1, 0.6, 0.8])\n",
    " [ 0.1,  0.6,  0.8]\n",
    ">>> wrapped_points = points.reshape(3, 1)\n",
    "[[ 0.1],\n",
    " [ 0.6],\n",
    " [ 0.8]]\n",
    ">>> distances = wrapped_points - points\n",
    "[[ 0. , -0.5, -0.7],\n",
    " [ 0.5,  0. , -0.2],\n",
    " [ 0.7,  0.2,  0. ]]\n",
    ">>> distances = np.abs(distances)\n",
    "[[ 0. ,  0.5,  0.7],\n",
    " [ 0.5,  0. ,  0.2],\n",
    " [ 0.7,  0.2,  0. ]]\n",
    ">>> i = np.arange(3)\n",
    "[0, 1, 2]\n",
    ">>> distances[i, i] = np.inf\n",
    "[[ inf,  0.5,  0.7],\n",
    " [ 0.5,  inf,  0.2],\n",
    " [ 0.7,  0.2,  inf]]\n",
    ">>> distances.argmin(1)\n",
    "[1, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Библиотека обработки и анализа данных. Работа с данными строится поверх библиотеки NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# $ pip3 install pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    " \n",
    "\n",
    "### Series\n",
    "Ordered dictionary with a name.\n",
    "\n",
    " \n",
    ">>> Series([1, 2], index=['x', 'y'], name='a')\n",
    "x    1\n",
    "y    2\n",
    "Name: a, dtype: int64\n",
    " \n",
    "\n",
    " \n",
    "<Sr> = Series(<list>)                         # Assigns RangeIndex starting at 0.\n",
    "<Sr> = Series(<dict>)                         # Takes dictionary's keys for index.\n",
    "<Sr> = Series(<dict/Series>, index=<list>)    # Only keeps items with keys specified in index.\n",
    " \n",
    "\n",
    " \n",
    "<el> = <Sr>.loc[key]                          # Or: <Sr>.iloc[index]\n",
    "<Sr> = <Sr>.loc[keys]                         # Or: <Sr>.iloc[indexes]\n",
    "<Sr> = <Sr>.loc[from_key : to_key_inclusive]  # Or: <Sr>.iloc[from_i : to_i_exclusive]\n",
    " \n",
    "\n",
    " \n",
    "<el> = <Sr>[key/index]                        # Or: <Sr>.key\n",
    "<Sr> = <Sr>[keys/indexes]                     # Or: <Sr>[<key_range/range>]\n",
    "<Sr> = <Sr>[bools]                            # Or: <Sr>.i/loc[bools]\n",
    " \n",
    "\n",
    " \n",
    "<Sr> = <Sr> ><== <el/Sr>                      # Returns a Series of bools.\n",
    "<Sr> = <Sr> +-*/ <el/Sr>                      # Items with non-matching keys get value NaN.\n",
    " \n",
    "\n",
    " \n",
    "<Sr> = <Sr>.append(<Sr>)                      # Or: pd.concat(<coll_of_Sr>)\n",
    "<Sr> = <Sr>.combine_first(<Sr>)               # Adds items that are not yet present.\n",
    "<Sr>.update(<Sr>)                             # Updates items that are already present.\n",
    " \n",
    "\n",
    " \n",
    "<Sr>.plot.line/area/bar/pie/hist()            # Generates a Matplotlib plot.\n",
    "matplotlib.pyplot.show()                      # Displays the plot. Also savefig(<path>).\n",
    " \n",
    "\n",
    "#### Series — Aggregate, Transform, Map:\n",
    " \n",
    "<el> = <Sr>.sum/max/mean/idxmax/all()         # Or: <Sr>.agg(lambda <Sr>: <el>)\n",
    "<Sr> = <Sr>.rank/diff/cumsum/ffill/interpl()  # Or: <Sr>.agg/transform(lambda <Sr>: <Sr>)\n",
    "<Sr> = <Sr>.fillna(<el>)                      # Or: <Sr>.agg/transform/map(lambda <el>: <el>)\n",
    " \n",
    "\n",
    " \n",
    ">>> sr = Series([1, 2], index=['x', 'y'])\n",
    "x    1\n",
    "y    2\n",
    " \n",
    "\n",
    " text\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |   ['sum']   | {'s': 'sum'}  |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| sr.apply(…)     |      3      |    sum  3   |     s  3      |\n",
    "| sr.agg(…)       |             |             |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'rank'   |   ['rank']  | {'r': 'rank'} |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| sr.apply(…)     |             |      rank   |               |\n",
    "| sr.agg(…)       |     x  1    |   x     1   |    r  x  1    |\n",
    "| sr.transform(…) |     y  2    |   y     2   |       y  2    |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    " \n",
    "Last result has a hierarchical index. Use `'<Sr>[key_1, key_2]'` to get its values.\n",
    "\n",
    "### DataFrame\n",
    "Table with labeled rows and columns.\n",
    "\n",
    " \n",
    ">>> DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    " \n",
    "\n",
    " \n",
    "<DF>    = DataFrame(<list_of_rows>)           # Rows can be either lists, dicts or series.\n",
    "<DF>    = DataFrame(<dict_of_columns>)        # Columns can be either lists, dicts or series.\n",
    " \n",
    "\n",
    " \n",
    "<el>    = <DF>.loc[row_key, column_key]       # Or: <DF>.iloc[row_index, column_index]\n",
    "<Sr/DF> = <DF>.loc[row_key/s]                 # Or: <DF>.iloc[row_index/es]\n",
    "<Sr/DF> = <DF>.loc[:, column_key/s]           # Or: <DF>.iloc[:, column_index/es]\n",
    "<DF>    = <DF>.loc[row_bools, column_bools]   # Or: <DF>.iloc[row_bools, column_bools]\n",
    " \n",
    "\n",
    " \n",
    "<Sr/DF> = <DF>[column_key/s]                  # Or: <DF>.column_key\n",
    "<DF>    = <DF>[row_bools]                     # Keeps rows as specified by bools.\n",
    "<DF>    = <DF>[<DF_of_bools>]                 # Assigns NaN to False values.\n",
    " \n",
    "\n",
    " \n",
    "<DF>    = <DF> ><== <el/Sr/DF>                # Returns DF of bools. Sr is treated as a row.\n",
    "<DF>    = <DF> +-*/ <el/Sr/DF>                # Items with non-matching keys get value NaN.\n",
    " \n",
    "\n",
    " \n",
    "<DF>    = <DF>.set_index(column_key)          # Replaces row keys with values from a column.\n",
    "<DF>    = <DF>.reset_index()                  # Moves row keys to a column named index.\n",
    "<DF>    = <DF>.sort_index(ascending=True)     # Sorts rows by row keys.\n",
    "<DF>    = <DF>.sort_values(column_key/s)      # Sorts rows by the passed column/s.\n",
    " \n",
    "\n",
    "#### DataFrame — Merge, Join, Concat:\n",
    " \n",
    ">>> l = DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    ">>> r = DataFrame([[4, 5], [6, 7]], index=['b', 'c'], columns=['y', 'z'])\n",
    "   y  z\n",
    "b  4  5\n",
    "c  6  7\n",
    " \n",
    "\n",
    " text\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "|                        |    'outer'    |   'inner'  |   'left'   |       Description        |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.merge(r, on='y',     |    x   y   z  | x   y   z  | x   y   z  | Joins/merges on column.  |\n",
    "|            how=…)      | 0  1   2   .  | 3   4   5  | 1   2   .  | Also accepts left_on and |\n",
    "|                        | 1  3   4   5  |            | 3   4   5  | right_on parameters.     |\n",
    "|                        | 2  .   6   7  |            |            | Uses 'inner' by default. |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.join(r, lsuffix='l', |    x yl yr  z |            | x yl yr  z | Joins/merges on row keys.|\n",
    "|           rsuffix='r', | a  1  2  .  . | x yl yr  z | 1  2  .  . | Uses 'left' by default.  |\n",
    "|           how=…)       | b  3  4  4  5 | 3  4  4  5 | 3  4  4  5 | If r is a series, it is  |\n",
    "|                        | c  .  .  6  7 |            |            | treated as a column.     |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| pd.concat([l, r],      |    x   y   z  |     y      |            | Adds rows at the bottom. |\n",
    "|           axis=0,      | a  1   2   .  |     2      |            | Uses 'outer' by default. |\n",
    "|           join=…)      | b  3   4   .  |     4      |            | A series is treated as a |\n",
    "|                        | b  .   4   5  |     4      |            | column. Use l.append(sr) |\n",
    "|                        | c  .   6   7  |     6      |            | to add a row instead.    |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| pd.concat([l, r],      |    x  y  y  z |            |            | Adds columns at the      |\n",
    "|           axis=1,      | a  1  2  .  . | x  y  y  z |            | right end. Uses 'outer'  |\n",
    "|           join=…)      | b  3  4  4  5 | 3  4  4  5 |            | by default. A series is  |\n",
    "|                        | c  .  .  6  7 |            |            | treated as a column.     |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.combine_first(r)     |    x   y   z  |            |            | Adds missing rows and    |\n",
    "|                        | a  1   2   .  |            |            | columns. Also updates    |\n",
    "|                        | b  3   4   5  |            |            | items that contain NaN.  |\n",
    "|                        | c  .   6   7  |            |            | R must be a DataFrame.   |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    " \n",
    "\n",
    "#### DataFrame — Aggregate, Transform, Map:\n",
    " \n",
    "<Sr> = <DF>.sum/max/mean/idxmax/all()         # Or: <DF>.apply/agg(lambda <Sr>: <el>)\n",
    "<DF> = <DF>.rank/diff/cumsum/ffill/interpl()  # Or: <DF>.apply/agg/transform(lambda <Sr>: <Sr>)\n",
    "<DF> = <DF>.fillna(<el>)                      # Or: <DF>.applymap(lambda <el>: <el>)\n",
    " \n",
    "All operations operate on columns by default. Pass `'axis=1'` to process the rows instead.\n",
    "\n",
    " \n",
    ">>> df = DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    " \n",
    "\n",
    " text\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |   ['sum']   | {'x': 'sum'}  |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| df.apply(…)     |             |       x  y  |               |\n",
    "| df.agg(…)       |     x  4    |  sum  4  6  |     x  4      |\n",
    "|                 |     y  6    |             |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'rank'   |   ['rank']  | {'x': 'rank'} |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| df.apply(…)     |      x  y   |      x    y |        x      |\n",
    "| df.agg(…)       |   a  1  1   |   rank rank |     a  1      |\n",
    "| df.transform(…) |   b  2  2   | a    1    1 |     b  2      |\n",
    "|                 |             | b    2    2 |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    " \n",
    "Use `'<DF>[col_key_1, col_key_2][row_key]'` to get the fifth result's values.\n",
    "\n",
    "#### DataFrame — Plot, Encode, Decode:\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "<DF>.plot.line/bar/hist/scatter([x=column_key, y=column_key/s]); plt.show()\n",
    " \n",
    "\n",
    " \n",
    "<DF> = pd.read_json/html('<str/path/url>')\n",
    "<DF> = pd.read_csv/pickle/excel('<path/url>')\n",
    "<DF> = pd.read_sql('<table_name/query>', <connection>)\n",
    "<DF> = pd.read_clipboard()\n",
    " \n",
    "\n",
    " \n",
    "<dict> = <DF>.to_dict(['d/l/s/sp/r/i'])\n",
    "<str>  = <DF>.to_json/html/csv/markdown/latex([<path>])\n",
    "<DF>.to_pickle/excel(<path>)\n",
    "<DF>.to_sql('<table_name>', <connection>)\n",
    " \n",
    "\n",
    "### GroupBy\n",
    "Object that groups together rows of a dataframe based on the value of the passed column.\n",
    "\n",
    " \n",
    ">>> df = DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 6]], index=list('abc'), columns=list('xyz'))\n",
    ">>> df.groupby('z').get_group(6)\n",
    "   x  y\n",
    "b  4  5\n",
    "c  7  8\n",
    " \n",
    "\n",
    " \n",
    "<GB> = <DF>.groupby(column_key/s)             # DF is split into groups based on passed column.\n",
    "<DF> = <GB>.apply(<func>)                     # Maps each group. Func can return DF, Sr or el.\n",
    "<GB> = <GB>[column_key]                       # A single column GB. All operations return a Sr.\n",
    " \n",
    "\n",
    "#### GroupBy — Aggregate, Transform, Map:\n",
    " \n",
    "<DF> = <GB>.sum/max/mean/idxmax/all()         # Or: <GB>.agg(lambda <Sr>: <el>)\n",
    "<DF> = <GB>.rank/diff/cumsum/ffill()          # Or: <GB>.transform(lambda <Sr>: <Sr>)\n",
    "<DF> = <GB>.fillna(<el>)                      # Or: <GB>.transform(lambda <Sr>: <Sr>)\n",
    " \n",
    "\n",
    " \n",
    ">>> gb = df.groupby('z')\n",
    "      x  y  z\n",
    "3: a  1  2  3\n",
    "6: b  4  5  6\n",
    "   c  7  8  6\n",
    " \n",
    "\n",
    " text\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |    'rank'   |   ['rank']  | {'x': 'rank'} |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "| gb.agg(…)       |      x   y  |      x  y   |      x    y |        x      |\n",
    "|                 |  z          |   a  1  1   |   rank rank |     a  1      |\n",
    "|                 |  3   1   2  |   b  1  1   | a    1    1 |     b  1      |\n",
    "|                 |  6  11  13  |   c  2  2   | b    1    1 |     c  2      |\n",
    "|                 |             |             | c    2    2 |               |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "| gb.transform(…) |      x   y  |      x  y   |             |               |\n",
    "|                 |  a   1   2  |   a  1  1   |             |               |\n",
    "|                 |  b  11  13  |   b  1  1   |             |               |\n",
    "|                 |  c  11  13  |   c  2  2   |             |               |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    " \n",
    "\n",
    "### Rolling\n",
    "Object for rolling window calculations.\n",
    "\n",
    " \n",
    "<R_Sr/R_DF/R_GB> = <Sr/DF/GB>.rolling(window_size)  # Also: `min_periods=None, center=False`.\n",
    "<R_Sr/R_DF>      = <R_DF/R_GB>[column_key/s]        # Or: <R>.column_key\n",
    "<Sr/DF/DF>       = <R_Sr/R_DF/R_GB>.sum/max/mean()  # Or: <R>.apply/agg(<agg_func/str>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
