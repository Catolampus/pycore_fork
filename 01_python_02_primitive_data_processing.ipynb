{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Срез (slice)\n",
    "\n",
    "Самый простой метод обработки данных, просто возвращает ту часть данных, местоположение которой (индексы) удовлетворяет определенным условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box with five \n",
      " box with five dozen liquor jugs \n",
      " Pack my box with five \n",
      " Pack my box with five dozen liquor jugs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a:str = \"Pack my box with five dozen liquor jugs\"\n",
    "\n",
    "start, stop = 8, 21\n",
    "\n",
    "b:str = a[start:stop]  # Значения от start до stop-1\n",
    "c:str = a[start:]  # Значения от start до конца структуры\n",
    "d:str = a[:stop]  # Значения от начала до stop-1\n",
    "e:str = a[:]  # Полная копия структуры\n",
    "\n",
    "print(b, \"\\n\",\n",
    "      c, \"\\n\",\n",
    "      d, \"\\n\",\n",
    "      e, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения start и stop могут быть отрицательными, это будет означать, что отсчет ведется от конца структуры. Можно также использовать значение step, чтобы на выход среза попали не все подряд данные из входной структуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pets \n",
      " step on no petS \n",
      "  petS \n",
      " Se nn es \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a:str = \"Step on no pets\"\n",
    "\n",
    "b:str = a[-4:]  # «Хвостик»\n",
    "c:str = a[::-1]  # Реверс входной строки\n",
    "d:str = a[4::-1]  # Первые четыре значения, реверсированы\n",
    "e:str = a[::2]  # Каждый второй символ\n",
    "\n",
    "print(b, \"\\n\",\n",
    "      c, \"\\n\",\n",
    "      d, \"\\n\",\n",
    "      e, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сортировка (sort, sorted)\n",
    "\n",
    "В сортировке всё самое интересное спрятано под капотом (мы ненадолго вернемся к этой теме чуть ниже, в разделе «Алгоритмы»), пока рассмотрим только Python-специфичный синтаксис.  \n",
    "Надо различать методы sort() и sorted(), первый сортирует данные in-place, второй порождает новую структуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2, 3, 1, 4] [1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a: list = [5, 2, 3, 1, 4]\n",
    "\n",
    "b: list = sorted(a)\n",
    "print(a, b)\n",
    "\n",
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И sort(), и sorted() имеют параметр key для указания функции, которая будет вызываться на каждом элементе. Если вам больше по нраву сортировка при помощи функции, принимающей два аргумента (или вы привыкли к cmp в Python 2), присмотритесь к functools.cmp_to_key()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Big', 'Dinosaurs', 'and', 'small', 'were']\n",
      "['and', 'Big', 'Dinosaurs', 'small', 'were']\n"
     ]
    }
   ],
   "source": [
    "# Регистрозависимое сравнение строк\n",
    "\n",
    "dinos: str = \"Dinosaurs were Big and small\"\n",
    "a = sorted(dinos.split())\n",
    "print(a)\n",
    "\n",
    "# Регистронезависимое сравнение строк\n",
    "\n",
    "dinos: str = \"Dinosaurs were Big and small\"\n",
    "b = sorted(dinos.split(), key=str.lower)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложносочиненные структуры данных можно сортировать по key=lambda el: el[1] или даже, например по key=lambda el: (el[1], el[0])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bisect и бинарный поиск\n",
    "\n",
    "Бинарный поиск существенно быстрее, чем обычный (см. раздел «Алгоритмы»), но требует предварительной сортировки коллекции, по которой осуществляется поиск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [1, 6, 8, 12, 19, 33]\n",
      "5\n",
      "[1, 6, 8, 12, 15, 19, 33]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "a: list[int] = [12, 6, 8, 19, 1, 33]\n",
    "\n",
    "a.sort()\n",
    "print(f\"Sorted: {a}\")\n",
    "\n",
    "print(bisect.bisect(a, 20))  # Найти индекс для потенциальной вставки\n",
    "\n",
    "bisect.insort(a, 15)  # Вставка значения в отсортированную последовательность\n",
    "print(a)\n",
    "\n",
    "# Бинарный поиск\n",
    "\n",
    "def binary_search(a, x, lo=0, hi=None):\n",
    "    if hi is None:\n",
    "        hi = len(a)\n",
    "\n",
    "    pos = bisect.bisect_left(a, x, lo, hi)\n",
    "    return pos if pos != hi and a[pos] == x else -1\n",
    "\n",
    "print(binary_search(a, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension\n",
    "\n",
    "Comprehension, которое переводится то как списковое включение, то как абстракция списков ([Википедия](https://ru.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BA%D0%BE%D0%B2%D0%BE%D0%B5_%D0%B2%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)), то вообще никак не переводится — способ компактного описания операций обработки списков (а примениительно к Python — еще и словарей, и множеств).\n",
    "\n",
    "Проще говоря, если вам нужно получить из списка другой список, включающий только те значения, которые удовлетворяют какому-то определенному условию, или вычисляемые из первого списка по каким-то определенным правилам, то comprehension — претендент на решение этой задачи № 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \n",
      " {8, 9, 6, 7} \n",
      " [5, 7, 9, 11, 13, 15, 17, 19, 21, 23] \n",
      " {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n"
     ]
    }
   ],
   "source": [
    "# Примеры Comprehension\n",
    "\n",
    "a = [i+1 for i in range(10)]  # list\n",
    "b  = {i for i in range(10) if i > 5}  # set\n",
    "c = (2*i+5 for i in range(10))  # iter\n",
    "d = {i: i**2 for i in range(10)}  # dict\n",
    "\n",
    "print(a,\"\\n\", b, \"\\n\", list(c), \"\\n\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут главное не перегнуть палку. Если запись comprehension становится слишком сложной и нечитаемой, возможно, стоит развернуть логику в «нормальный» цикл или в другой более удобочитаемый алгоритм. Comprehension соблазняет записывать «однострочникоми» достаточно сложные выражения, но не забывайте, что программист примерно 90 % времени читает код, и только 10 % пишет, так что если выражение будет плохочитаемым, вы усложните жизнь и себе, и свои коллегам.\n",
    "\n",
    "Есть более-менее [удачные](https://leetcode.com/problems/flipping-an-image/discuss/2378360/python-1-liner-988-speed-97-mem) «однострочники», есть быстрые, но [плохочитаемые](https://leetcode.com/problems/reverse-string-ii/discuss/2281269/python-fast-beats-984-and-short-almost-1-line-solution-with-python-38-features-pep572), написанные из спортивного интереса (это ссылки на решенные мной задачки на leetcode), желательно использовать comprehension в меру; лучше написать понятный развернутый алгоритм, чем непонятный, но обложенный пояснениями (если нет особых требований к производительности, само собой).\n",
    "\n",
    "Еще немного про list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lemon', 'Apple', 'Watermelon', 'Pear']\n",
      "['LEMON', 'APPLE', 'BANANA', 'KIWI', 'WATERMELON', 'PEAR']\n",
      "[['Lemon', 'Apple'], ['Banana', 'Kiwi'], ['Watermelon', 'Pear']]\n"
     ]
    }
   ],
   "source": [
    "# new_list = [expression for member in iterable (if conditional)]\n",
    "\n",
    "fruits: list = [\"Lemon\", \"Apple\", \"Banana\", \"Kiwi\", \"Watermelon\", \"Pear\"]\n",
    "\n",
    "e_fruits = [fruit for fruit in fruits if \"e\" in fruit]\n",
    "#                                     ☝ условие\n",
    "print(e_fruits)\n",
    "\n",
    "upper_fruits = [fruit.upper() for fruit in fruits]\n",
    "#                     ☝ выражение\n",
    "print(upper_fruits)\n",
    "\n",
    "# Пример разбиения списка на фрагменты одинаковой длины\n",
    "chunk_len = 2\n",
    "chunk_fruits = [fruits[i:i + chunk_len] for i in range(0, len(fruits), chunk_len)]\n",
    "print(chunk_fruits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Italy': 'Pizza', 'US': 'Hot-Dog', 'China': 'Dim Sum', 'South Korea': 'Kimchi'}\n",
      "{'Italy': 'Pizza', 'China': 'Dim Sum', 'South Korea': 'Kimchi'}\n",
      "{'China': 'Dim Sum'}\n",
      "{'US': 'Hot-Dog', 'China': 'Dim Sum'}\n"
     ]
    }
   ],
   "source": [
    "# new_dict = {expression for member in iterable (if conditional)}\n",
    "\n",
    "d: dict = {\"Italy\": \"Pizza\", \"US\": \"Hot-Dog\", \"China\": \"Dim Sum\", \"South Korea\": \"Kimchi\"}\n",
    "print(d)\n",
    "\n",
    "a: dict = {k: v for k, v in d.items() if \"i\" in v}  # Вернет новый словарь, отфильтрованный по значению\n",
    "print(a)\n",
    "\n",
    "b: dict = {k: v for k, v in d.items() if \"i\" in k}  # Вернет новый словарь, отфильтрованный по ключу\n",
    "print(b)\n",
    "\n",
    "c: dict = {k: v for k, v in d.items() if len(v) >= 7}  # Вернет новый словарь, отфильтрованный по длине значений\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте самостоятельно поиграться с set comprehension. Не забывайте, что set «переваривает» только уникальные значения, поэтому в результате вы можете получить не совсем то, на что рассчитывали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функциональное программирование (Map, Filter, Reduce, Partial)\n",
    "\n",
    "На случай, если начиная с этого момента и до конца текущего жизненного цикла вы собираетесь к месту и не месту использовать приёмы функционального программирования, чтобы сделать свой код «воистину крутым», просто процитирую вам Джоэля Граса, автора книги «Data Science: Наука о данных с нуля»: «В первом издании этой книги были представлены функции partial, map, reduce и filter языка Python. На своем пути к просветлению я понял, что этих функций лучше избегать, и их использование в книге было заменено включениями в список, циклами и другими, более Python'овскими конструкциями». Такие дела...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[6, 7, 8, 9]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "# Преобразует все входящие значения при помощи указанной функции\n",
    "iter1 = map(lambda x: x + 1, range(10))\n",
    "print(list(iter1))\n",
    "\n",
    "# Передает в выходной итератор только значения, удовлетворяющие условию\n",
    "iter2 = filter(lambda x: x > 5, range(10))\n",
    "print(list(iter2))\n",
    "\n",
    "# Применяет указанную функцию ко всей последовательности входных данных, сводя их к единственному значению\n",
    "a = functools.reduce(lambda out, x: out + x, range(10))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def sum(a,b):\n",
    "    return a + b\n",
    "\n",
    "add_const = functools.partial(sum, 10)\n",
    "\n",
    "print(add_const(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вам не сразу станет понятно, как работает функция partial (и зачем она нужна), не расстраивайтесь, вы не одиноки :). Вот, пожалуйста, тема на Stackoverflow: «[I am not able to get my head on how the partial works](https://stackoverflow.com/questions/15331726/how-does-functools-partial-do-what-it-does)». Там, кстати, есть совет, как partial могут быть полезны при организации pipe с включением функций, имеющих разное количество аргументов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any, All\n",
    "\n",
    "any() вернет True, если хотя бы один элемент итерируемой коллекции истинен, all() вернет True только в случае истинности всех элементов коллекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "animals = [\"Squirrel\", \"Beaver\", \"Fox\"]\n",
    "sentence = \"Bison likes squirrels and beavers\"\n",
    "\n",
    "any_animal: bool = any(animal.lower() in sentence.lower() for animal in animals)\n",
    "print(any_animal)\n",
    "\n",
    "all_animal: bool = all(animal.lower() in sentence.lower() for animal in animals)\n",
    "print(all_animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itertools\n",
    "\n",
    "Методы модуля itertools возвращают *итераторы*. В «нормальные» данные итераторы перегоняются при помощи for, next или list(). Итераторы могут быть бесконечными (порождаются при помощи count(), cycle() или repeat()) и конечными (accumulate(), chain(), takewhile() и другие). Лучше изучить их все, хотя бы поверхностно, потому что даже относительно редко употребляемый метод, например, какой-нибудь zip_longest(), иногда весьма и весьма пригождается, идеально ложась на поставленную задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1\n",
      "0.2\n",
      "['Wow!', 'Wow!', 'Wow!']\n",
      "1\n",
      "2\n",
      "1\n",
      "[(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import count, repeat, cycle, pairwise, chain\n",
    "\n",
    "# Итератор, возвращающий равномерно распределенные значения\n",
    "i1 = count(start=0, step=.1)\n",
    "print(next(i1))\n",
    "print(next(i1))\n",
    "print(next(i1))\n",
    "\n",
    "# Итератор, возвращающий один и тот же объект бесконечно, если не указано значение аргумента times\n",
    "i2 = repeat(\"Wow!\", times=3)\n",
    "print(list(i2))\n",
    "\n",
    "# Итератор, циклично и бесконечно возвращающий элементы итерируемого объекта\n",
    "i3 = cycle([1, 2])\n",
    "print(next(i3))\n",
    "print(next(i3))\n",
    "print(next(i3))\n",
    "\n",
    "# Возвращает элементы входной коллекции попарно\n",
    "i4 = pairwise([1, 2, 3, 4, 5])\n",
    "print(list(i4))\n",
    "\n",
    "# Итератор, формирующий из нескольких входных последовательностей одну общую\n",
    "i5 = chain([\"A\", \"B\", \"C\"],[\"D\", \"E\", \"F\"],[\"G\", \"H\", \"I\"])\n",
    "print(list(i5))\n",
    "# Кстати, такой же трюк можно провернуть при помощи обычной sum(), задав ей начальный параметр []\n",
    "a = sum([[\"A\", \"B\", \"C\"],[\"D\", \"E\", \"F\"],[\"G\", \"H\", \"I\"]], [])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комбинаторика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'x'), ('b', 'y'), ('b', 'z'), ('c', 'x'), ('c', 'y'), ('c', 'z')]\n",
      "[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n",
      "[('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'b'), ('b', 'c'), ('c', 'c')]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'c'), ('c', 'a'), ('c', 'b')]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, combinations, combinations_with_replacement, permutations\n",
    "\n",
    "# Создает множество, содержащее все упорядоченные пары элементов из входных множеств\n",
    "a = product(\"abc\", \"xyz\")\n",
    "print(list(a))\n",
    "\n",
    "b = product([0, 1], repeat=3)\n",
    "print(list(b))\n",
    "\n",
    "# Возвращает подпоследовательности длины r из элементов входного итерируемого объекта, повторяющиеся элементы не допускаются\n",
    "c = combinations(\"abc\", r=2)\n",
    "print(list(c))\n",
    "\n",
    "# Возвращает подпоследовательности длины r из элементов входного итерируемого объекта, повторяющиеся элементы допустимы\n",
    "d = combinations_with_replacement(\"abc\", r=2)\n",
    "print(list(d))\n",
    "\n",
    "# Выдает перестановки элементов итерируемого объекта\n",
    "e = permutations(\"abc\", r=2)\n",
    "print(list(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime encode\n",
    "\n",
    "Python использует Unix Epoch: \"1970-01-01 00:00 UTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-04 00:05:23.555000+00:00\n",
      " 2004-10-21 17:30:00\n",
      " 0274-10-16 00:00:00\n",
      " 1970-08-20 16:33:20.010000\n",
      " 1970-08-20 16:33:20.010000+05:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "dt1: datetime = datetime.fromisoformat(\"2021-10-04 00:05:23.555+00:00\")  # Может вызвать ValueError\n",
    "dt2: datetime = datetime.strptime(\"21/10/04 17:30\", \"%d/%m/%y %H:%M\")   # Подробнее про форматы - https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "dt3: datetime = datetime.fromordinal(100_000)  # 100000-й день от 1.1.0001\n",
    "dt4: datetime = datetime.fromtimestamp(20_000_000.01)  # Время в секундах с начала Unix Epoch\n",
    "\n",
    "tz = tzlocal()\n",
    "dt5: datetime = datetime.fromtimestamp(20_000_000.01, tz)  # С учетом часового пояса\n",
    "\n",
    "print (f\"{dt1}\\n {dt2}\\n {dt3}\\n {dt4}\\n {dt5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-06 17:50:38.041159\n",
      " 2022-09-06T17:50:38.041159\n",
      " 06/09/22 17:50\n",
      " 738404\n",
      " 1662468638.041159\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt1: datetime = datetime.today()\n",
    "\n",
    "s1: str = dt1.isoformat()\n",
    "s2: str = dt1.strftime(\"%d/%m/%y %H:%M\")  # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "i: int = dt1.toordinal()\n",
    "a: float = dt1.timestamp()  # Секунды с начала Unix Epoch\n",
    "\n",
    "print (f\"{dt1}\\n {s1}\\n {s2}\\n {i}\\n {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Арифметика datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11\n",
      " 2022-09-01 17:50:38.132916\n",
      " 14888 days, 17:50:38.132916\n",
      " 50 days, 0:00:00\n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, time, datetime, timedelta\n",
    "from dateutil.tz import UTC, tzlocal, gettz, datetime_exists, resolve_imaginary\n",
    "\n",
    "d: date  = date.today()\n",
    "dt1: datetime = datetime.today()\n",
    "dt2: datetime = datetime(year=1981, month=12, day=2)\n",
    "td1: timedelta = timedelta(days=5)\n",
    "td2: timedelta = timedelta(days=1)\n",
    "\n",
    "d = d + td1  # date = date ± timedelta\n",
    "dt3 = dt1 - td1  # datetime = datetime ± timedelta\n",
    "\n",
    "td3 = dt1 - dt2  # timedelta = datetime - datetime\n",
    "\n",
    "td4 = 10 * td1  # timedelta = const * timedelta\n",
    "c: float = td1/td2  # timedelta/timedelta\n",
    "\n",
    "print (f\"{d}\\n {dt3}\\n {td3}\\n {td4}\\n {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Операции над строками. lower(), upper(), capitalize() и title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelcase string\n",
      "CAMELCASE STRING\n",
      "Camelcase string\n",
      "Camelcase String\n"
     ]
    }
   ],
   "source": [
    "s: str = \"camelCase string\"\n",
    "\n",
    "print(s.lower())\n",
    "print(s.upper())\n",
    "print(s.capitalize())\n",
    "print(s.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~##A big blahblahblah##~~\n",
      "A big blahblahblah\n",
      "big blahblahblah\n",
      "big \n"
     ]
    }
   ],
   "source": [
    "s: str = \"  ~~##A big blahblahblah##~~  \"\n",
    "\n",
    "s = s.strip()  # Strips all whitespace characters from both ends\n",
    "print(s)\n",
    "\n",
    "s = s.strip(\"~#\")  # Strips all passed characters from both ends\n",
    "print(s)\n",
    "\n",
    "s = s.lstrip(\" A\")  # Strips all passed characters from left end\n",
    "print(s)\n",
    "\n",
    "s = s.rstrip(\"habl\")  # Strips all passed characters from right end\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Follow', 'the', 'white', 'rabbit,', 'Neo']\n",
      "['Follow the white rabbit', 'Neo']\n",
      "['Beware the Jabberwock, my son!', ' The jaws that bite, the claws that catch!']\n",
      "['Beware', 'the', 'Jabberwock, my son!\\n The jaws that bite, the claws that catch!'] ['Beware the Jabberwock, my son!\\n The jaws that bite, the claws', 'that', 'catch!']\n"
     ]
    }
   ],
   "source": [
    "s1: str = \"Follow the white rabbit, Neo\"\n",
    "\n",
    "c1 = s1.split()  # Splits on one or more whitespace characters\n",
    "print(c1)\n",
    "\n",
    "c2 = s1.split(sep=\", \", maxsplit=1)  # Splits on \"sep\" str at most \"maxsplit\" times\n",
    "print(c2)\n",
    "\n",
    "s2: str = \"Beware the Jabberwock, my son!\\n The jaws that bite, the claws that catch!\"\n",
    "\n",
    "c3 = s2.splitlines(keepends=False)  # On [\\n\\r\\f\\v\\x1c-\\x1e\\x85\\u2028\\u2029] and \\r\\n.\n",
    "print(c3)\n",
    "\n",
    "# split() vs rsplit()\n",
    "\n",
    "c4 = s2.split(maxsplit=2)\n",
    "c5 = s2.rsplit(maxsplit=2)\n",
    "\n",
    "print(c4, c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ord(), chr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 97\n",
      "b -> 98\n",
      "c -> 99\n",
      "A -> 65\n",
      "B -> 66\n",
      "C -> 67\n",
      "! -> 33\n",
      "72 -> H\n",
      "101 -> e\n",
      "108 -> l\n",
      "108 -> l\n",
      "111 -> o\n",
      "33 -> !\n"
     ]
    }
   ],
   "source": [
    "s1: str = \"abcABC!\"\n",
    "\n",
    "for ch in s1:\n",
    "    print(f\"{ch} -> {ord(ch)}\")  # Returns an integer representing the Unicode character\n",
    "\n",
    "nums = [72, 101, 108, 108, 111, 33]\n",
    "\n",
    "for num in nums:\n",
    "    print(f\"{num} -> {chr(num)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex\n",
    "\n",
    "Регулярные выражения — отдельная область знаний, и весьма-весьма непростая область. Тут, пожалуй, самое время для бородатой шутки про то, что «если вы решили свою проблему при помощи регулярных выражений — теперь у вас две проблемы».  \n",
    "\n",
    "Регулярки похожи на вхождение в воду на пляже острова Гуам в сторону Марианской впадины — даже когда вы думаете, что погрузились *реально* глубоко, то, скорее всего, вы просто не видите впередилежащей бездны. Но — знать регулярные выражения, хотя бы на начальном уровне, необходимо для решения целого класса задач, а то, что вёрткие регулярки периодически поворачиваются к вам своими, кхм... новыми гранями, придется простить, переварить и принять.  \n",
    "\n",
    "Вот [здесь](https://habr.com/ru/post/349860/) есть грамотное и методически выдержанное введение в тему, пока же посмотрим на основные возможности регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 5), match='a'> a\n",
      "None\n",
      "['a', 'A']\n",
      "234 bcd BCD 567\n",
      "['', '', '', ' abc ABC ', '', '', '']\n",
      " abc ABC "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s1: str = \"123 abc ABC 456\"\n",
    "\n",
    "m1 = re.search(\"[aA]\", s1)  # Ищет первое вхождение паттерна, при неудаче возвращает None\n",
    "print(m1, m1.group(0))\n",
    "\n",
    "m2 = re.fullmatch(\"[aA]\", s1)  # Проверка, подходит ли строка под шаблон\n",
    "print(m2)\n",
    "\n",
    "c1: list = re.findall(\"[aA]\", s1)  # Найти в строке все непересекающиеся шаблоны\n",
    "print(c1)\n",
    "\n",
    "def replacer(s):\n",
    "    return chr(ord(s[0]) + 1)  # Следующий символ из алфавита\n",
    "\n",
    "s2 = re.sub(\"\\w\", replacer, s1)  # Вы можете использовать функцию вместо шаблона\n",
    "print(s2)\n",
    "\n",
    "c2 = re.split(\"\\d\", s1)\n",
    "print(c2)\n",
    "\n",
    "iter = re.finditer(\"\\D\", s1)  # Итератор по непересекающимся шаблонам\n",
    "\n",
    "for ch in iter:\n",
    "    print(ch.group(0), end= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Connor\n",
      " John\n",
      " ('John', 'Connor')\n",
      " 0\n",
      " 11\n",
      " (0, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "m3 = re.match(r\"(\\w+) (\\w+)\", \"John Connor, leader of the Resistance\")\n",
    "\n",
    "s3: str = m3.group(0)  # Возвращает полное совпадение\n",
    "s4: str = m3.group(1)  # Возвращает часть в первых скобках\n",
    "t1: tuple = m3.groups()\n",
    "start: int = m3.start()  # Возвращает начальный индекс совпадения\n",
    "end: int = m3.end()  # Возвращает конечный индекс совпадения\n",
    "t2: tuple[int, int] = m3.span()  # Кортеж (start, end)\n",
    "\n",
    "print (f\"{s3}\\n {s4}\\n {t1}\\n {start}\\n {end}\\n {t2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Файлы\n",
    "\n",
    "Файловые операции стоят немного особняком от остальных методов обработки данных, так как подразумевают взаимодействие с неким постоянным энергонезависимым хранилищем данных. Так что если вам нужно сохранить данные *на завтра*, или, наоборот, нужно прочитать данные, которые вам предоставили *неделю назад*, то вам, очевидно, нужно будет работать с файлами. В файлах же осядет информация, которую мы передаем базам данных, но эту тему мы рассмотри ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from file!\n"
     ]
    }
   ],
   "source": [
    "f = open(\"f.txt\", mode='r', encoding=\"utf-8\", newline=None)\n",
    "\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай, если вы испытываете программистский зуд даже небольшой степени выраженности, напоминаю — эта статья в оригинале написана в Jupiter Notebook, все примеры кода интерактивны, не надо на них *смотреть*, их надо видоизменять, корректировать, дорабатывать.  \n",
    "Особенно это важно, если вам в приведенных сниппетах что-то непонятно. Обязательно запустите этот код в IDE, погоняйте пошаговый отладчик; только когда концы свяжутся, только когда вы поймете, как функционирует этот кусочек кода, только тогда промельнкнёт маленькая искорка и ваша квалификация как программиста немного подрастёт.  \n",
    "Исходный код скачивается [отсюда](https://github.com/amaargiru/pycore), VS Code лежит [здесь](https://code.visualstudio.com/download)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Режимы (mode):  \n",
    "\"r\" — чтение (поведение по умоолчанию)  \n",
    "\"w\" — запись (информация, ранее присутствующая в файле, будет стёрта)  \n",
    "\"x\" — эксклюзивное создание и запись; если файл уже существует, будет выброшено исключение FileExistsError  \n",
    "\"a\" — открытие с последующим добавлением в конец файла  \n",
    "\"w+\" — чтение и запись  \n",
    "\"r+\" — чтение и запись с начала файла  \n",
    "\"a+\" — чтение и запись с конца файла  \n",
    "\"t\" — текстовый режим (\"rt\", \"wt\" и т. д.; поведение по умолчанию)  \n",
    "\"b\" — двоичный режим (\"rb\", \"wb\", \"xb\" и т. д.)  \n",
    "\n",
    "encoding=None — будет использована кодировка по умолчанию (зависит от системы). Если нет специальных требований, просто используйте везде encoding=\"utf-8\".\n",
    "\n",
    "newline=None — при чтении системные символы конца строки будут конвертированы в \"\\n\"; при записи, наоборот, \"\\n\" будут конвертированы в системные символы конца строки.\n",
    "\n",
    "Возможные исключения при работе с файлами:  \n",
    "*FileNotFoundError* при чтении в режиме \"r\" или \"r+\".  \n",
    "*FileExistsError* при записи в режиме \"x\".  \n",
    "*IsADirectoryError*, *PermissionError* — в любом режиме.  \n",
    "\n",
    "### Чтение из файла\n",
    "\n",
    "Открывает файл и возвращает файловый объект.  \n",
    "Для работы с файлами лучше использовать менеджеры контекста (рассмотрены ниже), т. е. конструкции вида \"with open...\". Даже если что-то пойдет не так, как задумано (например, вы не обработаете исключение во время работы с файлом), менеджер контекста «зачистит хвосты», и ваша оплошность не отразится, например, на файловой системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "['Hello from file!']\n"
     ]
    }
   ],
   "source": [
    "with open(\"f.txt\", encoding=\"utf-8\") as f:\n",
    "    chars = f.read(5)  # Reads chars/bytes or until EOF\n",
    "    print(chars)\n",
    "\n",
    "    f.seek(0)  # Moves to the start of the file. Also seek(offset) and seek(±offset, anchor), where anchor is 0 for start, 1 for current position and 2 for end\n",
    "\n",
    "    lines: list[str] = f.readlines()  # Also readline()\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Hello from file!\")  # Или f.writelines(<collection>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пути (Paths)\n",
    "\n",
    "При работе с файлами не обойтись без манипулирования файловыми путями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Works\\amaargiru\\pycore\n",
      "c:\\Works\\amaargiru\\pycore\\f.txt\n",
      "f.txt c:\\Works\\amaargiru\\pycore ('c:\\\\Works\\\\amaargiru\\\\pycore\\\\f', '.txt')\n",
      "os.stat_result(st_mode=33206, st_ino=2251799814917120, st_dev=3628794147, st_nlink=1, st_uid=0, st_gid=0, st_size=16, st_atime=1662468638, st_mtime=1662468638, st_ctime=1661089564)\n",
      "True True False\n",
      "['.git', '.gitignore', '.pytest_cache', '01_python.ipynb', '01_python.md', '02_postgre.md', '03_architecture.md', '04_algorithms.ipynb', '04_algorithms.md', '05_admin_devops.md', '06_pytest_mock.ipynb', '06_pytest_mock.md', '07_fastapi.md', '08_flask.md', '1.bin', '1.json', 'compose_readme.bat', 'coupling_vs_cohesion.svg', 'f.txt', 'gitflow.svg', 'graph_for_dfs.jpg', 'pycallgraph3.png', 'readme.md']\n",
      "f .txt ('c:\\\\', 'Works', 'amaargiru', 'pycore', 'f.txt')\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, path, listdir\n",
    "from pathlib import Path\n",
    "\n",
    "s1: str = getcwd()  # Возвращает текущую рабочую директорию\n",
    "print(s1)\n",
    "\n",
    "s2: str = path.abspath(\"f.txt\")  # Возвращает полный путь\n",
    "print(s2)\n",
    "\n",
    "s3: str = path.basename(s2)  # Возвращает имя файла\n",
    "s4: str = path.dirname(s2)  # Возвращает путь без файла\n",
    "t1: tuple = path.splitext(s2)  # Возвращает кортеж из пути и имени файла\n",
    "print(s3, s4, t1)\n",
    "\n",
    "p = Path(s2)\n",
    "st = p.stat()\n",
    "print(st)\n",
    "\n",
    "b1: bool = p.exists()\n",
    "b2: bool = p.is_file()\n",
    "b3: bool = p.is_dir()\n",
    "print(b1, b2, b3)\n",
    "\n",
    "c: list = listdir(path=s1)  # Возвращает список имен файлов, находящихся по указанному пути\n",
    "print(c)\n",
    "\n",
    "s5: str = p.stem  # Возвращает имя файла без расширения\n",
    "s6: str  = p.suffix  # Возвращает расширение файла\n",
    "t2: tuple = p.parts  # Возвращает все элементы пути как отдельные строки\n",
    "print(s5, s6, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "Человекочитаемый формат для хранения и передачи данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"1\": \"Lemon\",\n",
      "  \"2\": \"Apple\",\n",
      "  \"3\": \"Banana!\"\n",
      "}\n",
      "{'1': 'Lemon', '2': 'Apple', '3': 'Banana!'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "d: dict = {1: \"Lemon\", 2: \"Apple\", 3: \"Banana!\"}\n",
    "\n",
    "object_as_string: str = json.dumps(d, indent=2)\n",
    "print(object_as_string)\n",
    "\n",
    "restored_object = json.loads(object_as_string)\n",
    "\n",
    "# Write object to JSON file\n",
    "with open(\"1.json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(d, file, indent=2)\n",
    "\n",
    "# Read object from JSON file\n",
    "with open(\"1.json\", encoding='utf-8') as file:\n",
    "    restored_from_file = json.load(file)\n",
    "    \n",
    "print(restored_from_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle\n",
    "\n",
    "Бинарный формат для хранения и передачи данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Lemon', 2: 'Apple', 3: 'Banana!'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "d: dict = {1: \"Lemon\", 2: \"Apple\", 3: \"Banana!\"}\n",
    "\n",
    "# Запись объекта в бинарный файл\n",
    "with open(\"1.bin\", \"wb\") as file:\n",
    "    pickle.dump(d, file)\n",
    "\n",
    "# Чтение объекта из файла\n",
    "with open(\"1.bin\", \"rb\") as file:\n",
    "    restored_from_file = pickle.load(file)\n",
    "\n",
    "print(restored_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Buffers\n",
    "Если вы хотите передавать и хранить данные, используя универсальную структуру, одинаково хорошо понимаемую всеми языками программирования (как JSON) и занимающую мало места (как Pickle), то можно посмотреть в сторону Protocol Buffers ([Wikipedia](https://en.wikipedia.org/wiki/Protocol_Buffers), [примеры для Python](https://developers.google.com/protocol-buffers/docs/pythontutorial)). Есть еще альтернативы, например, [FlatBuffers](https://google.github.io/flatbuffers/), [Apache Avro](https://avro.apache.org/) или [Thrift](https://thrift.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простейшие вычисления — Sum, Count, Min, Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "3\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a: list[int] = [1, 2, 3, 4, 5, 2, 2]\n",
    "\n",
    "s = sum(a)\n",
    "print(s)\n",
    "\n",
    "c = a.count(2)  # Вернет количество вхождений\n",
    "print(c)\n",
    "\n",
    "mn = min(a)\n",
    "print(mn)\n",
    "\n",
    "mx = max(a)\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присмотритесь к [встроенным функциям](https://docs.python.org/3/library/functions.html), там есть еще кое-что, касающееся элементарной математики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовая математика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power: 9.869604401089358\n",
      "Round: 3.14\n",
      "Int round: 300\n",
      "Abs: 3.141592653589793\n",
      "Complex abs: 14.142135623730951\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "\n",
    "a: float = pi ** 2  # Or pow(pi, 2)\n",
    "print(f\"Power: {a}\")\n",
    "\n",
    "b: float = round(pi, 2)\n",
    "print(f\"Round: {b}\")\n",
    "\n",
    "c: int = round(256, -2)\n",
    "print(f\"Int round: {c}\")\n",
    "\n",
    "d: float = abs(-pi)\n",
    "print(f\"Abs: {d}\")\n",
    "\n",
    "e: float = abs(10+10j)  # Or e: float = abs(complex(real=10, imag=10))\n",
    "print(f\"Complex abs: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Побитовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And: 0b00000000\n",
      "Or: 0b11111111\n",
      "Xor: 0b11111111\n",
      "Left shift: 0b10101010000\n",
      "Right shift: 0b00001010\n",
      "Not: 0b-1010110\n"
     ]
    }
   ],
   "source": [
    "a: int = 0b01010101\n",
    "b: int = 0b10101010\n",
    "\n",
    "print(f\"And: 0b{a&b:08b}\")\n",
    "print(f\"Or: 0b{a|b:08b}\")\n",
    "print(f\"Xor: 0b{a^b:08b}\")\n",
    "print(f\"Left shift: 0b{a << 4:08b}\")\n",
    "print(f\"Right shift: 0b{b >> 4:08b}\")\n",
    "print(f\"Not: 0b{~a:08b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет битов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4242 in binary format: 0b1000010010010\n",
      "Bit count: 4\n"
     ]
    }
   ],
   "source": [
    "a: int = 4242\n",
    "print(f\"{a} in binary format: 0b{a:b}\")\n",
    "\n",
    "c = a.bit_count()  # Returns the number of ones in the binary representation of the absolute value of the integer\n",
    "print(f\"Bit count: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "f = Fraction(\"0.2\").as_integer_ratio()\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Евклидово расстояние между двумя точками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.39588732276722\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "p1 = (0.22, 1, 12)\n",
    "p2 = (-0.12, 3, 7)\n",
    "\n",
    "print(math.dist(p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "Мини-язык для манипулирования массивами. На удачных сценариях работает в сотни раз быстрее встроенных функций. Еще более быстрая альтернатива работает на GPU, называется [CuPy](https://github.com/cupy/cupy) и опять-таки [обещает](https://medium.com/rapids-ai/single-gpu-cupy-speedups-ea99cbbb0cbb) стократный прирост производительности, только уже по сравнению с NumPy. Так что если вам нужен какой-нибудь быстрый [FFT](https://en.wikipedia.org/wiki/Fast_Fourier_transform) или еще какой числогрыз, то вы знаете, что делать.\n",
    "\n",
    "Небольшое отступление.\n",
    "\n",
    "Во-первых, тут мы переходим границу между встроенной функциональность языка и внешними библиотеками. Надо понимать, что успех Python во многом основан именно на богатстве его экосистемы (хотя, впрочем, тоже самое можно сказать и про JavaScript, и про C#); сам язык предоставляет богатую, но всё же ограниченную функциональность, в то время как функционал внешних библиотек практически безграничен, это как бесконечно разнообразные кубики Лего. Соответственно, очень часто для решения задачи не нужно реализовывать алгоритм с нуля, на чистом Python'е, достаточно подобрать нужную библиотеку.\n",
    "\n",
    "Во-вторых, популярность разных библиотек Python (в том числе и конкурирующих) сильно разнится. Например, NumPy — очень популярная библиотека, но в мире существуют буквально миллионы Python-разработчиков, которые *никогда* не работали с NumPy, просто в силу своего круга функциональных обязанностей.\n",
    "\n",
    "Для начинающего разработчика это представляет собой довольно нешуточную проблему — как конкретно двигаться вперед, какие библиотеки изучать, ведь знания чистого Python, как правило, недостаточно для формирования актуального резюме.  \n",
    "Дам небольшой совет. Ежегодно компания JetBrains (делающая среди прочего очень классную IDE PyCharm) проводит всемирный опрос Python-разработчиков, а потом выкладывает полученные результаты в виде так называемого [Python Developers Survey Results](https://lp.jetbrains.com/python-developers-survey-2021/). Например, если вы почитаете результы последнего исследовния, то найдете там довольно чёткие ориентиры, например, в разделе «Data science frameworks and libraries» в топе находятся NumPy, Pandas (рассмотрен ниже) и Matplotlib, в тестировании с большим отрывом лидирует pytest (смотри ниже), в других областях вперед вырываются Flask (Django на втором месте с крошечным отрывом), SQLAlchemy (vs Django ORM) и PostgreSQL (vs SQLite), про них мы тоже еще поговорим. Так что в целом, общее направление развития определить можно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<array> = np.array(<list/list_of_lists>)\n",
    "<array> = np.arange(from_inclusive, to_exclusive, ±step_size)\n",
    "<array> = np.ones(<shape>)\n",
    "<array> = np.random.randint(from_inclusive, to_exclusive, <shape>)\n",
    "\n",
    "<array>.shape = <shape>\n",
    "<view>  = <array>.reshape(<shape>)\n",
    "<view>  = np.broadcast_to(<array>, <shape>)\n",
    "\n",
    "<array> = <array>.sum(axis)\n",
    "indexes = <array>.argmin(axis)\n",
    "\n",
    "Shape is a tuple of dimension sizes.\n",
    "Axis is an index of the dimension that gets collapsed. Leftmost dimension has index 0.\n",
    "\n",
    "### Indexing\n",
    " bash\n",
    "<el>       = <2d_array>[row_index, column_index]\n",
    "<1d_view>  = <2d_array>[row_index]\n",
    "<1d_view>  = <2d_array>[:, column_index]\n",
    "\n",
    " bash\n",
    "<1d_array> = <2d_array>[row_indexes, column_indexes]\n",
    "<2d_array> = <2d_array>[row_indexes]\n",
    "<2d_array> = <2d_array>[:, column_indexes]\n",
    " \n",
    " bash\n",
    "<2d_bools> = <2d_array> ><== <el>\n",
    "<1d_array> = <2d_array>[<2d_bools>]\n",
    " \n",
    "### Broadcasting\n",
    "Broadcasting is a set of rules by which NumPy functions operate on arrays of different sizes and/or dimensions.\n",
    "\n",
    "left  = [[0.1], [0.6], [0.8]]        # Shape: (3, 1)\n",
    "right = [ 0.1 ,  0.6 ,  0.8 ]        # Shape: (3)\n",
    " \n",
    "#### 1. If array shapes differ in length, left-pad the shorter shape with ones:\n",
    " \n",
    "left  = [[0.1], [0.6], [0.8]]        # Shape: (3, 1)\n",
    "right = [[0.1 ,  0.6 ,  0.8]]        # Shape: (1, 3) <- !\n",
    "\n",
    "#### 2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:\n",
    " \n",
    "left  = [[0.1, 0.1, 0.1], [0.6, 0.6, 0.6], [0.8, 0.8, 0.8]]  # Shape: (3, 3) <- !\n",
    "right = [[0.1, 0.6, 0.8], [0.1, 0.6, 0.8], [0.1, 0.6, 0.8]]  # Shape: (3, 3) <- !\n",
    "\n",
    "#### 3. If neither non-matching dimension has size 1, raise an error.\n",
    "\n",
    "### Example\n",
    "#### For each point returns index of its nearest point (`[0.1, 0.6, 0.8] => [1, 2, 1]`):\n",
    "\n",
    ">>> points = np.array([0.1, 0.6, 0.8])\n",
    " [ 0.1,  0.6,  0.8]\n",
    ">>> wrapped_points = points.reshape(3, 1)\n",
    "[[ 0.1],\n",
    " [ 0.6],\n",
    " [ 0.8]]\n",
    ">>> distances = wrapped_points - points\n",
    "[[ 0. , -0.5, -0.7],\n",
    " [ 0.5,  0. , -0.2],\n",
    " [ 0.7,  0.2,  0. ]]\n",
    ">>> distances = np.abs(distances)\n",
    "[[ 0. ,  0.5,  0.7],\n",
    " [ 0.5,  0. ,  0.2],\n",
    " [ 0.7,  0.2,  0. ]]\n",
    ">>> i = np.arange(3)\n",
    "[0, 1, 2]\n",
    ">>> distances[i, i] = np.inf\n",
    "[[ inf,  0.5,  0.7],\n",
    " [ 0.5,  inf,  0.2],\n",
    " [ 0.7,  0.2,  inf]]\n",
    ">>> distances.argmin(1)\n",
    "[1, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Библиотека обработки и анализа данных. Работа с данными строится поверх библиотеки NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $ pip3 install pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "### Series\n",
    "Ordered dictionary with a name.\n",
    "\n",
    ">>> Series([1, 2], index=['x', 'y'], name='a')\n",
    "x    1\n",
    "y    2\n",
    "Name: a, dtype: int64\n",
    "\n",
    "<Sr> = Series(<list>)                         # Assigns RangeIndex starting at 0.\n",
    "<Sr> = Series(<dict>)                         # Takes dictionary's keys for index.\n",
    "<Sr> = Series(<dict/Series>, index=<list>)    # Only keeps items with keys specified in index.\n",
    "\n",
    "<el> = <Sr>.loc[key]                          # Or: <Sr>.iloc[index]\n",
    "<Sr> = <Sr>.loc[keys]                         # Or: <Sr>.iloc[indexes]\n",
    "<Sr> = <Sr>.loc[from_key : to_key_inclusive]  # Or: <Sr>.iloc[from_i : to_i_exclusive]\n",
    "\n",
    "<el> = <Sr>[key/index]                        # Or: <Sr>.key\n",
    "<Sr> = <Sr>[keys/indexes]                     # Or: <Sr>[<key_range/range>]\n",
    "<Sr> = <Sr>[bools]                            # Or: <Sr>.i/loc[bools]\n",
    "\n",
    "<Sr> = <Sr> ><== <el/Sr>                      # Returns a Series of bools.\n",
    "<Sr> = <Sr> +-*/ <el/Sr>                      # Items with non-matching keys get value NaN.\n",
    "\n",
    "<Sr> = <Sr>.append(<Sr>)                      # Or: pd.concat(<coll_of_Sr>)\n",
    "<Sr> = <Sr>.combine_first(<Sr>)               # Adds items that are not yet present.\n",
    "<Sr>.update(<Sr>)                             # Updates items that are already present.\n",
    "\n",
    "<Sr>.plot.line/area/bar/pie/hist()            # Generates a Matplotlib plot.\n",
    "matplotlib.pyplot.show()                      # Displays the plot. Also savefig(<path>).\n",
    "\n",
    "#### Series — Aggregate, Transform, Map:\n",
    "\n",
    "<el> = <Sr>.sum/max/mean/idxmax/all()         # Or: <Sr>.agg(lambda <Sr>: <el>)\n",
    "<Sr> = <Sr>.rank/diff/cumsum/ffill/interpl()  # Or: <Sr>.agg/transform(lambda <Sr>: <Sr>)\n",
    "<Sr> = <Sr>.fillna(<el>)                      # Or: <Sr>.agg/transform/map(lambda <el>: <el>)\n",
    "\n",
    ">>> sr = Series([1, 2], index=['x', 'y'])\n",
    "x    1\n",
    "y    2\n",
    " \n",
    " text\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |   ['sum']   | {'s': 'sum'}  |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| sr.apply(…)     |      3      |    sum  3   |     s  3      |\n",
    "| sr.agg(…)       |             |             |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'rank'   |   ['rank']  | {'r': 'rank'} |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| sr.apply(…)     |             |      rank   |               |\n",
    "| sr.agg(…)       |     x  1    |   x     1   |    r  x  1    |\n",
    "| sr.transform(…) |     y  2    |   y     2   |       y  2    |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    " \n",
    "Last result has a hierarchical index. Use `'<Sr>[key_1, key_2]'` to get its values.\n",
    "\n",
    "### DataFrame\n",
    "Table with labeled rows and columns.\n",
    "\n",
    ">>> DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    "\n",
    "<DF>    = DataFrame(<list_of_rows>)           # Rows can be either lists, dicts or series.\n",
    "<DF>    = DataFrame(<dict_of_columns>)        # Columns can be either lists, dicts or series.\n",
    "\n",
    "<el>    = <DF>.loc[row_key, column_key]       # Or: <DF>.iloc[row_index, column_index]\n",
    "<Sr/DF> = <DF>.loc[row_key/s]                 # Or: <DF>.iloc[row_index/es]\n",
    "<Sr/DF> = <DF>.loc[:, column_key/s]           # Or: <DF>.iloc[:, column_index/es]\n",
    "<DF>    = <DF>.loc[row_bools, column_bools]   # Or: <DF>.iloc[row_bools, column_bools]\n",
    "\n",
    "<Sr/DF> = <DF>[column_key/s]                  # Or: <DF>.column_key\n",
    "<DF>    = <DF>[row_bools]                     # Keeps rows as specified by bools.\n",
    "<DF>    = <DF>[<DF_of_bools>]                 # Assigns NaN to False values.\n",
    "\n",
    "<DF>    = <DF> ><== <el/Sr/DF>                # Returns DF of bools. Sr is treated as a row.\n",
    "<DF>    = <DF> +-*/ <el/Sr/DF>                # Items with non-matching keys get value NaN.\n",
    "\n",
    "<DF>    = <DF>.set_index(column_key)          # Replaces row keys with values from a column.\n",
    "<DF>    = <DF>.reset_index()                  # Moves row keys to a column named index.\n",
    "<DF>    = <DF>.sort_index(ascending=True)     # Sorts rows by row keys.\n",
    "<DF>    = <DF>.sort_values(column_key/s)      # Sorts rows by the passed column/s.\n",
    "\n",
    "#### DataFrame — Merge, Join, Concat:\n",
    " \n",
    ">>> l = DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    ">>> r = DataFrame([[4, 5], [6, 7]], index=['b', 'c'], columns=['y', 'z'])\n",
    "   y  z\n",
    "b  4  5\n",
    "c  6  7\n",
    "\n",
    " text\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "|                        |    'outer'    |   'inner'  |   'left'   |       Description        |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.merge(r, on='y',     |    x   y   z  | x   y   z  | x   y   z  | Joins/merges on column.  |\n",
    "|            how=…)      | 0  1   2   .  | 3   4   5  | 1   2   .  | Also accepts left_on and |\n",
    "|                        | 1  3   4   5  |            | 3   4   5  | right_on parameters.     |\n",
    "|                        | 2  .   6   7  |            |            | Uses 'inner' by default. |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.join(r, lsuffix='l', |    x yl yr  z |            | x yl yr  z | Joins/merges on row keys.|\n",
    "|           rsuffix='r', | a  1  2  .  . | x yl yr  z | 1  2  .  . | Uses 'left' by default.  |\n",
    "|           how=…)       | b  3  4  4  5 | 3  4  4  5 | 3  4  4  5 | If r is a series, it is  |\n",
    "|                        | c  .  .  6  7 |            |            | treated as a column.     |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| pd.concat([l, r],      |    x   y   z  |     y      |            | Adds rows at the bottom. |\n",
    "|           axis=0,      | a  1   2   .  |     2      |            | Uses 'outer' by default. |\n",
    "|           join=…)      | b  3   4   .  |     4      |            | A series is treated as a |\n",
    "|                        | b  .   4   5  |     4      |            | column. Use l.append(sr) |\n",
    "|                        | c  .   6   7  |     6      |            | to add a row instead.    |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| pd.concat([l, r],      |    x  y  y  z |            |            | Adds columns at the      |\n",
    "|           axis=1,      | a  1  2  .  . | x  y  y  z |            | right end. Uses 'outer'  |\n",
    "|           join=…)      | b  3  4  4  5 | 3  4  4  5 |            | by default. A series is  |\n",
    "|                        | c  .  .  6  7 |            |            | treated as a column.     |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "| l.combine_first(r)     |    x   y   z  |            |            | Adds missing rows and    |\n",
    "|                        | a  1   2   .  |            |            | columns. Also updates    |\n",
    "|                        | b  3   4   5  |            |            | items that contain NaN.  |\n",
    "|                        | c  .   6   7  |            |            | R must be a DataFrame.   |\n",
    "+------------------------+---------------+------------+------------+--------------------------+\n",
    "\n",
    "#### DataFrame — Aggregate, Transform, Map:\n",
    " \n",
    "<Sr> = <DF>.sum/max/mean/idxmax/all()         # Or: <DF>.apply/agg(lambda <Sr>: <el>)\n",
    "<DF> = <DF>.rank/diff/cumsum/ffill/interpl()  # Or: <DF>.apply/agg/transform(lambda <Sr>: <Sr>)\n",
    "<DF> = <DF>.fillna(<el>)                      # Or: <DF>.applymap(lambda <el>: <el>)\n",
    " \n",
    "All operations operate on columns by default. Pass `'axis=1'` to process the rows instead.\n",
    "\n",
    ">>> df = DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])\n",
    "   x  y\n",
    "a  1  2\n",
    "b  3  4\n",
    "\n",
    " text\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |   ['sum']   | {'x': 'sum'}  |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| df.apply(…)     |             |       x  y  |               |\n",
    "| df.agg(…)       |     x  4    |  sum  4  6  |     x  4      |\n",
    "|                 |     y  6    |             |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "|                 |    'rank'   |   ['rank']  | {'x': 'rank'} |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    "| df.apply(…)     |      x  y   |      x    y |        x      |\n",
    "| df.agg(…)       |   a  1  1   |   rank rank |     a  1      |\n",
    "| df.transform(…) |   b  2  2   | a    1    1 |     b  2      |\n",
    "|                 |             | b    2    2 |               |\n",
    "+-----------------+-------------+-------------+---------------+\n",
    " \n",
    "Use `'<DF>[col_key_1, col_key_2][row_key]'` to get the fifth result's values.\n",
    "\n",
    "#### DataFrame — Plot, Encode, Decode:\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "<DF>.plot.line/bar/hist/scatter([x=column_key, y=column_key/s]); plt.show()\n",
    " \n",
    "<DF> = pd.read_json/html('<str/path/url>')\n",
    "<DF> = pd.read_csv/pickle/excel('<path/url>')\n",
    "<DF> = pd.read_sql('<table_name/query>', <connection>)\n",
    "<DF> = pd.read_clipboard()\n",
    " \n",
    "<dict> = <DF>.to_dict(['d/l/s/sp/r/i'])\n",
    "<str>  = <DF>.to_json/html/csv/markdown/latex([<path>])\n",
    "<DF>.to_pickle/excel(<path>)\n",
    "<DF>.to_sql('<table_name>', <connection>)\n",
    " \n",
    "### GroupBy\n",
    "Object that groups together rows of a dataframe based on the value of the passed column.\n",
    " \n",
    ">>> df = DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 6]], index=list('abc'), columns=list('xyz'))\n",
    ">>> df.groupby('z').get_group(6)\n",
    "   x  y\n",
    "b  4  5\n",
    "c  7  8\n",
    " \n",
    "<GB> = <DF>.groupby(column_key/s)             # DF is split into groups based on passed column.\n",
    "<DF> = <GB>.apply(<func>)                     # Maps each group. Func can return DF, Sr or el.\n",
    "<GB> = <GB>[column_key]                       # A single column GB. All operations return a Sr.\n",
    " \n",
    "#### GroupBy — Aggregate, Transform, Map:\n",
    " \n",
    "<DF> = <GB>.sum/max/mean/idxmax/all()         # Or: <GB>.agg(lambda <Sr>: <el>)\n",
    "<DF> = <GB>.rank/diff/cumsum/ffill()          # Or: <GB>.transform(lambda <Sr>: <Sr>)\n",
    "<DF> = <GB>.fillna(<el>)                      # Or: <GB>.transform(lambda <Sr>: <Sr>)\n",
    " \n",
    ">>> gb = df.groupby('z')\n",
    "      x  y  z\n",
    "3: a  1  2  3\n",
    "6: b  4  5  6\n",
    "   c  7  8  6\n",
    "\n",
    " text\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "|                 |    'sum'    |    'rank'   |   ['rank']  | {'x': 'rank'} |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "| gb.agg(…)       |      x   y  |      x  y   |      x    y |        x      |\n",
    "|                 |  z          |   a  1  1   |   rank rank |     a  1      |\n",
    "|                 |  3   1   2  |   b  1  1   | a    1    1 |     b  1      |\n",
    "|                 |  6  11  13  |   c  2  2   | b    1    1 |     c  2      |\n",
    "|                 |             |             | c    2    2 |               |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "| gb.transform(…) |      x   y  |      x  y   |             |               |\n",
    "|                 |  a   1   2  |   a  1  1   |             |               |\n",
    "|                 |  b  11  13  |   b  1  1   |             |               |\n",
    "|                 |  c  11  13  |   c  2  2   |             |               |\n",
    "+-----------------+-------------+-------------+-------------+---------------+\n",
    "\n",
    "### Rolling\n",
    "Object for rolling window calculations.\n",
    "\n",
    "<R_Sr/R_DF/R_GB> = <Sr/DF/GB>.rolling(window_size)  # Also: `min_periods=None, center=False`.\n",
    "<R_Sr/R_DF>      = <R_DF/R_GB>[column_key/s]        # Or: <R>.column_key\n",
    "<Sr/DF/DF>       = <R_Sr/R_DF/R_GB>.sum/max/mean()  # Or: <R>.apply/agg(<agg_func/str>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
